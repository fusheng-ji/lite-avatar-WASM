/**
 * LiteAvatar WebGPU æµè§ˆå™¨ç‰ˆæœ¬
 * å‚è€ƒ HeadTTS é¡¹ç›®å®ç°æ–¹å¼
 */

// è¯´æ˜ï¼šæœ¬é¡¹ç›®å®ç°å…¨å‰ç«¯ç‰¹å¾æå–ï¼ˆå®Œå…¨æœ¬åœ°åŒ–ï¼‰ï¼š
// 1. ä½¿ç”¨ ParaformerFrontend æå– fbank + LFR + CMVN ç‰¹å¾
// 2. ä½¿ç”¨ paraformer_hidden.onnx (603MB FP32) æ¨¡å‹è·å– hidden states
// 3. æ—¶é—´æ’å€¼åˆ°ç›®æ ‡å¸§æ•°

class LiteAvatarWeb {
    constructor() {
        this.audio2mouthModel = null;
        this.encoderModel = null;
        this.generatorModel = null;
        this.paraformerModel = null; // Paraformer hidden states æ¨¡å‹
        this.frontend = null; // Paraformer å‰ç«¯ç‰¹å¾æå–å™¨
        this.audioContext = null;
        this.isInitialized = false;
        this.avatarData = null;
        this.audioFile = null;
        this.bgVideoFrames = [];
        this.refFrames = [];
        this.neutralPose = null;
        this.faceBox = null;
        this.mergeMask = null;
        this.processedAudioBuffer = null; // å­˜å‚¨å¤„ç†åçš„éŸ³é¢‘ï¼ˆ16kHz, å•å£°é“ï¼‰
        this.useFrontendFeatureExtraction = true; // å¯ç”¨å…¨å‰ç«¯ç‰¹å¾æå–ï¼ˆå”¯ä¸€æ¨¡å¼ï¼‰
        
        // å½•éŸ³ç›¸å…³çŠ¶æ€
        this.mediaRecorder = null;
        this.audioStream = null;
        this.recordedChunks = [];
        this.isRecording = false;
        
        this.initUI();
        this.checkReady();
    }

    initUI() {
        // æ–‡ä»¶è¾“å…¥
        const audioFileInput = document.getElementById('audioFile');
        const avatarDataInput = document.getElementById('avatarData');
        const generateBtn = document.getElementById('generateBtn');
        const useDefaultDataBtn = document.getElementById('useDefaultData');
        const fileInputLabel = document.getElementById('fileInputLabel');
        const dataInputLabel = document.getElementById('dataInputLabel');

        // äº‹ä»¶ç›‘å¬
        audioFileInput.addEventListener('change', (e) => this.handleAudioFile(e));
        avatarDataInput.addEventListener('change', (e) => this.handleAvatarData(e));
        generateBtn.addEventListener('click', () => this.generateVideo());
        useDefaultDataBtn.addEventListener('click', () => this.loadDefaultData());
        
        // é»˜è®¤ç¤ºä¾‹éŸ³é¢‘æŒ‰é’®
        const useDefaultAudioBtn = document.getElementById('useDefaultAudio');
        if (useDefaultAudioBtn) {
            useDefaultAudioBtn.addEventListener('click', () => this.loadDefaultAudio());
        }
        
        // å½•éŸ³æŒ‰é’®
        const recordAudioBtn = document.getElementById('recordAudioBtn');
        const stopRecordBtn = document.getElementById('stopRecordBtn');
        if (recordAudioBtn) {
            recordAudioBtn.addEventListener('click', () => this.startRecording());
        }
        if (stopRecordBtn) {
            stopRecordBtn.addEventListener('click', () => this.stopRecording());
        }

        // é¢„åŠ è½½æ¨¡å‹æŒ‰é’®
        const preloadModelsBtn = document.getElementById('preloadModelsBtn');
        if (preloadModelsBtn) {
            preloadModelsBtn.addEventListener('click', () => this.preloadModels());
        }

        // ç‚¹å‡»æ ‡ç­¾æ—¶è§¦å‘æ–‡ä»¶é€‰æ‹©
        fileInputLabel.addEventListener('click', (e) => {
            e.preventDefault();
            audioFileInput.click();
        });

        dataInputLabel.addEventListener('click', (e) => {
            e.preventDefault();
            avatarDataInput.click();
        });

        // æ‹–æ‹½æ”¯æŒ - éŸ³é¢‘æ–‡ä»¶
        fileInputLabel.addEventListener('dragover', (e) => {
            e.preventDefault();
            e.stopPropagation();
            fileInputLabel.style.background = '#f0f0ff';
        });
        fileInputLabel.addEventListener('dragleave', (e) => {
            e.preventDefault();
            e.stopPropagation();
            fileInputLabel.style.background = 'white';
        });
        fileInputLabel.addEventListener('drop', (e) => {
            e.preventDefault();
            e.stopPropagation();
            fileInputLabel.style.background = 'white';
            if (e.dataTransfer.files.length > 0) {
                // åˆ›å»ºæ–°çš„ FileListï¼ˆæµè§ˆå™¨é™åˆ¶ï¼Œä½¿ç”¨ DataTransferï¼‰
                const dt = new DataTransfer();
                dt.items.add(e.dataTransfer.files[0]);
                audioFileInput.files = dt.files;
                this.handleAudioFile({ target: { files: dt.files } });
            }
        });

        // æ‹–æ‹½æ”¯æŒ - Avatar æ•°æ®
        dataInputLabel.addEventListener('dragover', (e) => {
            e.preventDefault();
            e.stopPropagation();
            dataInputLabel.style.background = '#f0f0ff';
        });
        dataInputLabel.addEventListener('dragleave', (e) => {
            e.preventDefault();
            e.stopPropagation();
            dataInputLabel.style.background = 'white';
        });
        dataInputLabel.addEventListener('drop', (e) => {
            e.preventDefault();
            e.stopPropagation();
            dataInputLabel.style.background = 'white';
            // æ³¨æ„ï¼šæ‹–æ‹½ç›®å½•éœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œå»ºè®®ä½¿ç”¨ç‚¹å‡»é€‰æ‹©
            this.updateStatus('', 'è¯·ä½¿ç”¨"ç‚¹å‡»é€‰æ‹©"æŒ‰é’®æ¥é€‰æ‹©ç›®å½•');
        });
    }

    async handleAudioFile(event) {
        const file = event.target.files[0];
        if (!file) {
            this.checkReady();
            return;
        }

        const audioInfo = document.getElementById('audioInfo');
        audioInfo.className = 'status';
        audioInfo.textContent = `å·²é€‰æ‹©: ${file.name} (${(file.size / 1024 / 1024).toFixed(2)} MB)`;
        audioInfo.classList.remove('hidden');

        // éªŒè¯éŸ³é¢‘æ–‡ä»¶å¹¶è·å–è¯¦ç»†ä¿¡æ¯
        try {
            // ä½¿ç”¨ AudioContext è·å–å‡†ç¡®çš„é‡‡æ ·ç‡ä¿¡æ¯
            const arrayBuffer = await file.arrayBuffer();
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
            
            // æ˜¾ç¤ºéŸ³é¢‘ä¿¡æ¯
            const info = `é‡‡æ ·ç‡: ${audioBuffer.sampleRate}Hz, é€šé“æ•°: ${audioBuffer.numberOfChannels}, æ—¶é•¿: ${audioBuffer.duration.toFixed(2)}ç§’`;
            audioInfo.textContent += ` | ${info}`;
            
            // å…³é—­ AudioContext ä»¥é‡Šæ”¾èµ„æº
            await audioContext.close();
            
            // ä¿å­˜éŸ³é¢‘æ–‡ä»¶å¼•ç”¨
            this.audioFile = file;
        } catch (error) {
            console.warn('æ— æ³•è¯»å–éŸ³é¢‘æ–‡ä»¶è¯¦ç»†ä¿¡æ¯:', error);
            // å›é€€åˆ° Audio å…ƒç´ æ–¹æ³•
            try {
                const audio = new Audio();
                audio.src = URL.createObjectURL(file);
                await new Promise((resolve, reject) => {
                    audio.addEventListener('loadedmetadata', () => {
                        const info = `æ—¶é•¿: ${audio.duration.toFixed(2)}ç§’`;
                        audioInfo.textContent += ` | ${info}`;
                        resolve();
                    });
                    audio.addEventListener('error', reject);
                    setTimeout(() => reject(new Error('è¶…æ—¶')), 5000);
                });
                this.audioFile = file;
            } catch (fallbackError) {
                audioInfo.className = 'status error';
                audioInfo.textContent = 'æ— æ³•è¯»å–éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯';
                this.audioFile = null;
            }
        }
        
        // æ£€æŸ¥æ˜¯å¦å¯ä»¥å¯ç”¨ç”ŸæˆæŒ‰é’®
        this.checkReady();
    }

    async handleAvatarData(event) {
        const files = Array.from(event.target.files);
        const avatarDataInfo = document.getElementById('avatarDataInfo');
        const dataInputText = document.getElementById('dataInputText');
        
        console.log('Avatar æ•°æ®ä¸Šä¼ :', files.length, 'ä¸ªæ–‡ä»¶');
        
        if (files.length === 0) {
            this.avatarData = null;
            avatarDataInfo.className = 'status error';
            avatarDataInfo.textContent = 'æœªé€‰æ‹©ä»»ä½•æ–‡ä»¶';
            avatarDataInfo.classList.remove('hidden');
            this.updateStatus('error', 'æœªé€‰æ‹©ä»»ä½•æ–‡ä»¶');
            this.checkReady();
            return;
        }
        
        this.avatarData = this.organizeFiles(files);
        const fileCount = Object.keys(this.avatarData).length;
        console.log('Avatar æ•°æ®å·²ç»„ç»‡:', fileCount, 'ä¸ªæ–‡ä»¶');
        console.log('æ–‡ä»¶åˆ—è¡¨:', Object.keys(this.avatarData).slice(0, 10), '...');
        
        // æ›´æ–°çŠ¶æ€æ˜¾ç¤º
        const info = `Avatar æ•°æ®å·²åŠ è½½ (${fileCount} ä¸ªæ–‡ä»¶)`;
        avatarDataInfo.textContent = info;
        avatarDataInfo.className = 'status success';
        avatarDataInfo.classList.remove('hidden');
        
        // æ›´æ–°æ–‡ä»¶è¾“å…¥æ˜¾ç¤º
        dataInputText.textContent = `å·²é€‰æ‹©: ${files.length} ä¸ªæ–‡ä»¶`;
        
        this.updateStatus('success', info);
        
        // æ£€æŸ¥æ˜¯å¦å¯ä»¥å¯ç”¨ç”ŸæˆæŒ‰é’®
        this.checkReady();
    }

    organizeFiles(files) {
        const organized = {};
        files.forEach(file => {
            const path = file.webkitRelativePath || file.name;
            // ä¿ç•™ç›®å½•ç»“æ„ï¼Œç‰¹åˆ«æ˜¯ ref_frames/
            if (path.includes('/')) {
                // å¯¹äºç›®å½•ä¸­çš„æ–‡ä»¶ï¼Œä¿ç•™ç›¸å¯¹è·¯å¾„
                organized[path] = file;
            } else {
                // å¯¹äºæ ¹ç›®å½•çš„æ–‡ä»¶ï¼Œåªä½¿ç”¨æ–‡ä»¶å
                organized[file.name] = file;
            }
        });
        return organized;
    }

    async loadDefaultData() {
        const avatarDataInfo = document.getElementById('avatarDataInfo');
        const dataInputText = document.getElementById('dataInputText');
        
        avatarDataInfo.className = 'status';
        avatarDataInfo.textContent = 'æ­£åœ¨åŠ è½½é»˜è®¤ç¤ºä¾‹æ•°æ®...';
        avatarDataInfo.classList.remove('hidden');
        this.updateStatus('', 'æ­£åœ¨åŠ è½½é»˜è®¤ç¤ºä¾‹æ•°æ®...');
        
        try {
            // åŠ è½½é»˜è®¤æ•°æ®ç›®å½•
            const defaultDataPath = './data/preload';
            this.avatarData = await this.loadDefaultAvatarData(defaultDataPath);
            
            if (this.avatarData && Object.keys(this.avatarData).length > 0) {
                const fileCount = Object.keys(this.avatarData).length;
                const info = `å·²åŠ è½½é»˜è®¤ç¤ºä¾‹æ•°æ® (${fileCount} ä¸ªæ–‡ä»¶)`;
                
                // æ›´æ–°çŠ¶æ€æ˜¾ç¤º
                avatarDataInfo.textContent = info;
                avatarDataInfo.className = 'status success';
                
                // æ›´æ–°æ–‡ä»¶è¾“å…¥æ˜¾ç¤º
                dataInputText.textContent = `å·²é€‰æ‹©: é»˜è®¤ç¤ºä¾‹æ•°æ® (${fileCount} ä¸ªæ–‡ä»¶)`;
                
                this.updateStatus('success', info);
                console.log('é»˜è®¤æ•°æ®åŠ è½½æˆåŠŸ:', fileCount, 'ä¸ªæ–‡ä»¶');
            } else {
                throw new Error('æœªèƒ½åŠ è½½é»˜è®¤æ•°æ®');
            }
        } catch (error) {
            console.error('åŠ è½½é»˜è®¤æ•°æ®å¤±è´¥:', error);
            avatarDataInfo.className = 'status error';
            avatarDataInfo.textContent = `åŠ è½½é»˜è®¤æ•°æ®å¤±è´¥: ${error.message}`;
            this.updateStatus('error', `åŠ è½½é»˜è®¤æ•°æ®å¤±è´¥: ${error.message}`);
            this.avatarData = null;
        }
        
        this.checkReady();
    }

    async loadDefaultAudio() {
        const audioInfo = document.getElementById('audioInfo');
        audioInfo.className = 'status';
        audioInfo.textContent = 'æ­£åœ¨åŠ è½½é»˜è®¤ç¤ºä¾‹éŸ³é¢‘...';
        audioInfo.classList.remove('hidden');
        
        try {
            // åŠ è½½é»˜è®¤éŸ³é¢‘æ–‡ä»¶
            const audioUrl = './data/test.wav';
            const response = await fetch(audioUrl);
            
            if (!response.ok) {
                throw new Error(`HTTP ${response.status}: ${response.statusText}`);
            }
            
            const blob = await response.blob();
            const file = new File([blob], 'test.wav', { type: 'audio/wav' });
            
            // ä½¿ç”¨ AudioContext è·å–éŸ³é¢‘ä¿¡æ¯
            const arrayBuffer = await file.arrayBuffer();
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
            
            // æ˜¾ç¤ºéŸ³é¢‘ä¿¡æ¯
            const info = `é‡‡æ ·ç‡: ${audioBuffer.sampleRate}Hz, é€šé“æ•°: ${audioBuffer.numberOfChannels}, æ—¶é•¿: ${audioBuffer.duration.toFixed(2)}ç§’`;
            audioInfo.textContent = `å·²åŠ è½½é»˜è®¤ç¤ºä¾‹éŸ³é¢‘: test.wav | ${info}`;
            audioInfo.className = 'status success';
            
            // å…³é—­ AudioContext ä»¥é‡Šæ”¾èµ„æº
            await audioContext.close();
            
            // ä¿å­˜éŸ³é¢‘æ–‡ä»¶å¼•ç”¨
            this.audioFile = file;
            
            // æ›´æ–°æ–‡ä»¶è¾“å…¥æ˜¾ç¤º
            const fileInputText = document.getElementById('fileInputText');
            fileInputText.textContent = `å·²é€‰æ‹©: test.wav (é»˜è®¤ç¤ºä¾‹éŸ³é¢‘)`;
            
            console.log('é»˜è®¤éŸ³é¢‘åŠ è½½æˆåŠŸ:', file.name, info);
        } catch (error) {
            console.error('åŠ è½½é»˜è®¤éŸ³é¢‘å¤±è´¥:', error);
            audioInfo.className = 'status error';
            audioInfo.textContent = `åŠ è½½é»˜è®¤éŸ³é¢‘å¤±è´¥: ${error.message}`;
            this.audioFile = null;
        }
        
        // æ£€æŸ¥æ˜¯å¦å¯ä»¥å¯ç”¨ç”ŸæˆæŒ‰é’®
        this.checkReady();
    }

    async startRecording() {
        const recordingStatus = document.getElementById('recordingStatus');
        const recordAudioBtn = document.getElementById('recordAudioBtn');
        const stopRecordBtn = document.getElementById('stopRecordBtn');
        const audioInfo = document.getElementById('audioInfo');
        
        try {
            // è¯·æ±‚éº¦å…‹é£æƒé™
            this.audioStream = await navigator.mediaDevices.getUserMedia({ 
                audio: {
                    sampleRate: 16000,  // ç›®æ ‡é‡‡æ ·ç‡
                    channelCount: 1,     // å•å£°é“
                    echoCancellation: true,
                    noiseSuppression: true,
                    autoGainControl: true
                } 
            });
            
            // åˆå§‹åŒ–å½•éŸ³
            this.recordedChunks = [];
            const options = { mimeType: 'audio/webm' };
            
            // å°è¯•ä½¿ç”¨æ›´å¥½çš„ç¼–ç æ ¼å¼
            if (MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
                options.mimeType = 'audio/webm;codecs=opus';
            } else if (MediaRecorder.isTypeSupported('audio/webm')) {
                options.mimeType = 'audio/webm';
            } else if (MediaRecorder.isTypeSupported('audio/mp4')) {
                options.mimeType = 'audio/mp4';
            }
            
            this.mediaRecorder = new MediaRecorder(this.audioStream, options);
            
            // å½•éŸ³æ•°æ®æ”¶é›†
            this.mediaRecorder.ondataavailable = (event) => {
                if (event.data.size > 0) {
                    this.recordedChunks.push(event.data);
                }
            };
            
            // å½•éŸ³åœæ­¢å¤„ç†
            this.mediaRecorder.onstop = async () => {
                try {
                    // åˆ›å»º Blob
                    const blob = new Blob(this.recordedChunks, { type: options.mimeType });
                    
                    // è½¬æ¢ä¸º WAV æ ¼å¼ï¼ˆå› ä¸ºåç»­å¤„ç†éœ€è¦ï¼‰
                    const audioBuffer = await this.convertBlobToAudioBuffer(blob);
                    const wavBlob = this.audioBufferToWav(audioBuffer);
                    
                    // åˆ›å»º File å¯¹è±¡
                    const file = new File([wavBlob], `recording_${Date.now()}.wav`, { type: 'audio/wav' });
                    
                    // æ˜¾ç¤ºéŸ³é¢‘ä¿¡æ¯
                    const info = `é‡‡æ ·ç‡: ${audioBuffer.sampleRate}Hz, é€šé“æ•°: ${audioBuffer.numberOfChannels}, æ—¶é•¿: ${audioBuffer.duration.toFixed(2)}ç§’`;
                    audioInfo.textContent = `å·²å½•åˆ¶éŸ³é¢‘ | ${info}`;
                    audioInfo.className = 'status success';
                    audioInfo.classList.remove('hidden');
                    
                    // æ›´æ–°æ–‡ä»¶è¾“å…¥æ˜¾ç¤º
                    const fileInputText = document.getElementById('fileInputText');
                    fileInputText.textContent = `å·²é€‰æ‹©: ${file.name} (éº¦å…‹é£å½•éŸ³)`;
                    
                    // ä¿å­˜éŸ³é¢‘æ–‡ä»¶å¼•ç”¨
                    this.audioFile = file;
                    
                    // åœæ­¢éŸ³é¢‘æµ
                    this.audioStream.getTracks().forEach(track => track.stop());
                    this.audioStream = null;
                    
                    console.log('å½•éŸ³å®Œæˆ:', file.name, info);
                    
                    // æ£€æŸ¥æ˜¯å¦å¯ä»¥å¯ç”¨ç”ŸæˆæŒ‰é’®
                    this.checkReady();
                } catch (error) {
                    console.error('å¤„ç†å½•éŸ³æ•°æ®å¤±è´¥:', error);
                    recordingStatus.className = 'status error';
                    recordingStatus.textContent = `å¤„ç†å½•éŸ³å¤±è´¥: ${error.message}`;
                }
            };
            
            // é”™è¯¯å¤„ç†
            this.mediaRecorder.onerror = (error) => {
                console.error('å½•éŸ³é”™è¯¯:', error);
                recordingStatus.className = 'status error';
                recordingStatus.textContent = `å½•éŸ³é”™è¯¯: ${error.message || 'æœªçŸ¥é”™è¯¯'}`;
                this.stopRecording();
            };
            
            // å¼€å§‹å½•éŸ³
            this.mediaRecorder.start(100); // æ¯100msæ”¶é›†ä¸€æ¬¡æ•°æ®
            this.isRecording = true;
            
            // æ›´æ–°UI
            recordAudioBtn.style.display = 'none';
            stopRecordBtn.style.display = 'inline-block';
            recordingStatus.className = 'status';
            recordingStatus.textContent = 'ğŸ¤ æ­£åœ¨å½•éŸ³... ç‚¹å‡»"åœæ­¢å½•éŸ³"ç»“æŸ';
            recordingStatus.classList.remove('hidden');
            audioInfo.classList.add('hidden');
            
            console.log('å¼€å§‹å½•éŸ³...');
        } catch (error) {
            console.error('å¯åŠ¨å½•éŸ³å¤±è´¥:', error);
            recordingStatus.className = 'status error';
            recordingStatus.textContent = `æ— æ³•è®¿é—®éº¦å…‹é£: ${error.message || 'è¯·æ£€æŸ¥æµè§ˆå™¨æƒé™è®¾ç½®'}`;
            recordingStatus.classList.remove('hidden');
            
            if (this.audioStream) {
                this.audioStream.getTracks().forEach(track => track.stop());
                this.audioStream = null;
            }
        }
    }

    stopRecording() {
        const recordingStatus = document.getElementById('recordingStatus');
        const recordAudioBtn = document.getElementById('recordAudioBtn');
        const stopRecordBtn = document.getElementById('stopRecordBtn');
        
        if (this.mediaRecorder && this.isRecording) {
            this.mediaRecorder.stop();
            this.isRecording = false;
            
            // æ›´æ–°UI
            recordAudioBtn.style.display = 'inline-block';
            stopRecordBtn.style.display = 'none';
            recordingStatus.textContent = 'æ­£åœ¨å¤„ç†å½•éŸ³...';
        }
    }

    async convertBlobToAudioBuffer(blob) {
        const arrayBuffer = await blob.arrayBuffer();
        const audioContext = new (window.AudioContext || window.webkitAudioContext)({
            sampleRate: 16000  // ç›®æ ‡é‡‡æ ·ç‡
        });
        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
        await audioContext.close();
        return audioBuffer;
    }

    audioBufferToWav(audioBuffer) {
        const numChannels = audioBuffer.numberOfChannels;
        const sampleRate = audioBuffer.sampleRate;
        const format = 1; // PCM
        const bitDepth = 16;
        
        const bytesPerSample = bitDepth / 8;
        const blockAlign = numChannels * bytesPerSample;
        
        const length = audioBuffer.length;
        const buffer = new ArrayBuffer(44 + length * numChannels * bytesPerSample);
        const view = new DataView(buffer);
        
        // WAV æ–‡ä»¶å¤´
        const writeString = (offset, string) => {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        };
        
        writeString(0, 'RIFF');
        view.setUint32(4, 36 + length * numChannels * bytesPerSample, true);
        writeString(8, 'WAVE');
        writeString(12, 'fmt ');
        view.setUint32(16, 16, true); // fmt chunk size
        view.setUint16(20, format, true);
        view.setUint16(22, numChannels, true);
        view.setUint32(24, sampleRate, true);
        view.setUint32(28, sampleRate * blockAlign, true);
        view.setUint16(32, blockAlign, true);
        view.setUint16(34, bitDepth, true);
        writeString(36, 'data');
        view.setUint32(40, length * numChannels * bytesPerSample, true);
        
        // å†™å…¥éŸ³é¢‘æ•°æ®
        let offset = 44;
        for (let i = 0; i < length; i++) {
            for (let channel = 0; channel < numChannels; channel++) {
                const sample = Math.max(-1, Math.min(1, audioBuffer.getChannelData(channel)[i]));
                view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7fff, true);
                offset += 2;
            }
        }
        
        return new Blob([buffer], { type: 'audio/wav' });
    }

    async loadDefaultAvatarData(dataPath) {
        const avatarData = {};
        const filesToLoad = [
            'bg_video.mp4',
            'face_box.txt',
            'neutral_pose.npy',
            'net_decode.pt',
            'net_encode.pt'
        ];

        // åŠ è½½ä¸»è¦æ–‡ä»¶
        for (const fileName of filesToLoad) {
            try {
                const response = await fetch(`${dataPath}/${fileName}`);
                if (response.ok) {
                    const blob = await response.blob();
                    avatarData[fileName] = new File([blob], fileName, { type: blob.type });
                    console.log(`âœ“ å·²åŠ è½½: ${fileName}`);
                } else {
                    console.warn(`âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®: ${fileName}`);
                }
            } catch (error) {
                console.warn(`âš ï¸ åŠ è½½ ${fileName} å¤±è´¥:`, error);
            }
        }

        // åŠ è½½å‚è€ƒå¸§ï¼ˆref_frames ç›®å½•ï¼‰
        const refFramesPath = `${dataPath}/ref_frames`;
        let refFrameIndex = 0;
        let hasMoreFrames = true;
        const maxFrames = 150; // é™åˆ¶åŠ è½½çš„å¸§æ•°

        while (hasMoreFrames && refFrameIndex < maxFrames) {
            const frameFileName = `ref_${String(refFrameIndex).padStart(5, '0')}.jpg`;
            try {
                const response = await fetch(`${refFramesPath}/${frameFileName}`);
                if (response.ok) {
                    const blob = await response.blob();
                    avatarData[`ref_frames/${frameFileName}`] = new File([blob], frameFileName, { type: 'image/jpeg' });
                    refFrameIndex++;
                } else {
                    // å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåœæ­¢åŠ è½½
                    hasMoreFrames = false;
                }
            } catch (error) {
                // å¦‚æœå‡ºé”™ï¼Œåœæ­¢åŠ è½½
                hasMoreFrames = false;
            }
        }

        console.log(`âœ“ å·²åŠ è½½ ${refFrameIndex} ä¸ªå‚è€ƒå¸§`);

        if (Object.keys(avatarData).length === 0) {
            throw new Error('æœªèƒ½åŠ è½½ä»»ä½•æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„æ˜¯å¦æ­£ç¡®');
        }

        return avatarData;
    }
    
    checkReady() {
        const generateBtn = document.getElementById('generateBtn');
        const audioFileInput = document.getElementById('audioFile');
        const audioFile = audioFileInput?.files[0] || this.audioFile;
        const hasAudio = !!audioFile;
        const hasAvatarData = !!this.avatarData && Object.keys(this.avatarData).length > 0;
        
        // è°ƒè¯•ä¿¡æ¯
        console.log('æ£€æŸ¥æŒ‰é’®çŠ¶æ€:', {
            hasAudio,
            hasAvatarData,
            audioFile: audioFile?.name,
            avatarDataFiles: this.avatarData ? Object.keys(this.avatarData).length : 0
        });
        
        // å¦‚æœéŸ³é¢‘å’Œ Avatar æ•°æ®éƒ½å·²å‡†å¤‡å¥½ï¼Œå¯ç”¨æŒ‰é’®
        if (hasAudio && hasAvatarData) {
            generateBtn.disabled = false;
            generateBtn.textContent = 'ç”Ÿæˆè§†é¢‘';
            console.log('âœ“ æŒ‰é’®å·²å¯ç”¨');
        } else {
            generateBtn.disabled = true;
            if (!hasAudio && !hasAvatarData) {
                generateBtn.textContent = 'è¯·å…ˆä¸Šä¼ éŸ³é¢‘æ–‡ä»¶å’Œ Avatar æ•°æ®';
            } else if (!hasAudio) {
                generateBtn.textContent = 'è¯·å…ˆä¸Šä¼ éŸ³é¢‘æ–‡ä»¶';
            } else if (!hasAvatarData) {
                generateBtn.textContent = 'è¯·å…ˆåŠ è½½ Avatar æ•°æ®';
            }
            console.log('âœ— æŒ‰é’®ä»ç¦ç”¨:', { hasAudio, hasAvatarData });
        }
    }

    async initializeModels() {
        if (this.isInitialized) return;

        this.updateStatus('', 'æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹...');

        const getModelPath = (relativePath) => {
            // å¦‚æœé…ç½®ä¸­å·²ç»æ˜¯å®Œæ•´ URLï¼ˆä»¥ http:// æˆ– https:// å¼€å¤´ï¼‰ï¼Œç›´æ¥è¿”å›
            if (relativePath && (relativePath.startsWith('http://') || relativePath.startsWith('https://'))) {
                return relativePath;
            }
            // å¦‚æœæœ‰ CDN base URLï¼Œæ‹¼æ¥è·¯å¾„
            const cdnBaseUrl = window.appConfig?.cdnBaseUrl;
            if (cdnBaseUrl) {
                return cdnBaseUrl.replace(/\/$/, '') + '/' + relativePath.replace(/^\.\//, '');
            }
            // å¦åˆ™è¿”å›ç›¸å¯¹è·¯å¾„
            return relativePath;
        };

        try {
            if (ort?.env?.wasm) {
                ort.env.wasm.wasmPaths = 'https://cdn.jsdelivr.net/npm/onnxruntime-web@1.20.1/dist/';
                ort.env.wasm.numThreads = 1;
                ort.env.wasm.simd = true;
            }

            // æ‰€æœ‰æ¨¡å‹éƒ½ä½¿ç”¨ WASM åç«¯ï¼Œå› ä¸º WebGPU å¯¹ Concat ç®—å­æœ‰åµŒå¥—æ·±åº¦é™åˆ¶ï¼ˆ127ï¼‰
            const wasmOnlySessionOptions = {
                executionProviders: ['wasm'],
                graphOptimizationLevel: 'all',
                wasmPaths: {
                    'ort-wasm.wasm': 'https://cdn.jsdelivr.net/npm/onnxruntime-web@1.20.1/dist/ort-wasm.wasm',
                    'ort-wasm-simd.wasm': 'https://cdn.jsdelivr.net/npm/onnxruntime-web@1.20.1/dist/ort-wasm-simd.wasm',
                    'ort-wasm-threaded.wasm': 'https://cdn.jsdelivr.net/npm/onnxruntime-web@1.20.1/dist/ort-wasm-threaded.wasm',
                    'ort-wasm-simd-threaded.wasm': 'https://cdn.jsdelivr.net/npm/onnxruntime-web@1.20.1/dist/ort-wasm-simd-threaded.wasm'
                },
                numThreads: 4,
                logSeverityLevel: 2,
                logVerbosityLevel: 0
            };
            
            this.updateStatus('', 'æ­£åœ¨åŠ è½½ Paraformer æ¨¡å‹ï¼ˆFP32ï¼ŒWASM åç«¯ï¼‰...');
            try {
                const paraformerSessionOptions = {
                    executionProviders: ['wasm'],
                    graphOptimizationLevel: 'all',
                    wasmPaths: {
                        'ort-wasm.wasm': 'https://cdn.jsdelivr.net/npm/onnxruntime-web@1.20.1/dist/ort-wasm.wasm',
                        'ort-wasm-simd.wasm': 'https://cdn.jsdelivr.net/npm/onnxruntime-web@1.20.1/dist/ort-wasm-simd.wasm',
                        'ort-wasm-threaded.wasm': 'https://cdn.jsdelivr.net/npm/onnxruntime-web@1.20.1/dist/ort-wasm-threaded.wasm',
                        'ort-wasm-simd-threaded.wasm': 'https://cdn.jsdelivr.net/npm/onnxruntime-web@1.20.1/dist/ort-wasm-simd-threaded.wasm'
                    },
                    numThreads: 4,
                    logSeverityLevel: 2,
                    logVerbosityLevel: 0
                };
                
                const modelPath = getModelPath(window.appConfig?.modelPaths?.paraformerFp32 || './weights/paraformer_hidden.onnx');
                this.paraformerModel = await ort.InferenceSession.create(modelPath, paraformerSessionOptions);
                console.log('âœ“ Paraformer FP32 æ¨¡å‹å·²åŠ è½½ï¼ˆ603MBï¼‰');
                console.log('Paraformer inputs:', this.paraformerModel.inputNames);
                console.log('Paraformer outputs:', this.paraformerModel.outputNames);
                
                // åˆå§‹åŒ–å‰ç«¯ç‰¹å¾æå–å™¨
                this.frontend = new ParaformerFrontend({
                    sampleRate: 16000,
                    nMels: 80,
                    frameLength: 400,
                    frameShift: 160,
                    windowType: 'hamming',
                    lfrM: 7,
                    lfrN: 6
                });
                console.log('âœ“ Paraformer å‰ç«¯ç‰¹å¾æå–å™¨å·²åˆå§‹åŒ–');
                this.useFrontendFeatureExtraction = true;
                console.log('âœ“ å‰ç«¯ç‰¹å¾æå–å·²å¯ç”¨');
            } catch (error) {
                console.error('Paraformer æ¨¡å‹åŠ è½½å¤±è´¥:', error);
                console.error('é”™è¯¯è¯¦æƒ…:', error.message, error.stack);
                this.paraformerModel = null;
                this.frontend = null;
                this.useFrontendFeatureExtraction = false;
                throw new Error(`å‰ç«¯ç‰¹å¾æå–æ¨¡å‹åŠ è½½å¤±è´¥: ${error.message}ã€‚è¯·ç¡®ä¿ weights/paraformer_hidden.onnx æ–‡ä»¶å­˜åœ¨ä¸”å¯è®¿é—®ã€‚`);
            }

            this.updateStatus('', 'æ­£åœ¨åŠ è½½éŸ³é¢‘åˆ°å˜´éƒ¨æ¨¡å‹...');
            const audio2mouthPath = getModelPath(window.appConfig?.modelPaths?.audio2mouth || './weights/model_1.onnx');
            this.audio2mouthModel = await ort.InferenceSession.create(
                audio2mouthPath,
                wasmOnlySessionOptions
            );
            console.log('âœ“ audio2mouth æ¨¡å‹å·²åŠ è½½ï¼ˆWASM åç«¯ï¼‰');

            this.updateStatus('', 'æ­£åœ¨åŠ è½½é¢éƒ¨ç”Ÿæˆæ¨¡å‹...');
            try {
                this.encoderModel = await ort.InferenceSession.create('./data/preload/net_encode.onnx', wasmOnlySessionOptions);
                console.log('âœ“ ç¼–ç å™¨æ¨¡å‹å·²åŠ è½½ï¼ˆWASM åç«¯ï¼‰');
            } catch (error) {
                console.warn('ç¼–ç å™¨æ¨¡å‹åŠ è½½å¤±è´¥:', error.message);
                this.encoderModel = null;
            }
            
            try {
                this.generatorModel = await ort.InferenceSession.create('./data/preload/net_decode.onnx', wasmOnlySessionOptions);
                console.log('âœ“ ç”Ÿæˆå™¨æ¨¡å‹å·²åŠ è½½ï¼ˆWASM åç«¯ï¼‰');
            } catch (error) {
                console.warn('ç”Ÿæˆå™¨æ¨¡å‹åŠ è½½å¤±è´¥:', error.message);
                this.generatorModel = null;
            }

            this.isInitialized = true;
            this.updateStatus('success', 'æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼');
        } catch (error) {
            this.updateStatus('error', `æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: ${error.message}`);
            throw error;
        }
    }

    async preloadModels() {
        const preloadBtn = document.getElementById('preloadModelsBtn');
        const preloadStatus = document.getElementById('preloadStatus');
        const t = window.i18n ? window.i18n.t : (key) => key;
        
        if (this.isInitialized) {
            preloadStatus.className = 'status success';
            preloadStatus.textContent = t('preloadAlready');
            preloadStatus.classList.remove('hidden');
            if (preloadBtn) {
                preloadBtn.disabled = true;
                preloadBtn.textContent = t('preloadAlready');
            }
            return;
        }

        if (preloadBtn) {
            preloadBtn.disabled = true;
            preloadBtn.textContent = 'â³ ' + t('preloadLoading');
        }

        preloadStatus.className = 'status';
        preloadStatus.textContent = t('preloadLoading');
        preloadStatus.classList.remove('hidden');

        try {
            await this.initializeModels();
            preloadStatus.className = 'status success';
            preloadStatus.textContent = t('preloadSuccess');
            if (preloadBtn) {
                preloadBtn.textContent = t('preloadAlready');
            }
            this.updateStatus('success', t('preloadSuccess'));
        } catch (error) {
            console.error('æ¨¡å‹é¢„åŠ è½½å¤±è´¥:', error);
            preloadStatus.className = 'status error';
            preloadStatus.textContent = t('preloadError') + ': ' + error.message;
            if (preloadBtn) {
                preloadBtn.disabled = false;
                preloadBtn.textContent = t('preloadBtn');
            }
            this.updateStatus('error', t('preloadError') + ': ' + error.message);
        }
    }

    async loadAvatarData(dataDirOrFiles) {
        this.updateStatus('', 'æ­£åœ¨å¤„ç† Avatar æ•°æ®...');

        try {
            let avatarDataFiles = null;

            // å¦‚æœä¼ å…¥çš„æ˜¯æ–‡ä»¶å¯¹è±¡å­—å…¸ï¼Œç›´æ¥ä½¿ç”¨
            if (typeof dataDirOrFiles === 'object' && !Array.isArray(dataDirOrFiles) && dataDirOrFiles.constructor === Object) {
                avatarDataFiles = dataDirOrFiles;
            } else if (typeof dataDirOrFiles === 'string') {
                // å¦‚æœæ˜¯è·¯å¾„å­—ç¬¦ä¸²ï¼Œéœ€è¦åŠ è½½
                avatarDataFiles = await this.loadDefaultAvatarData(dataDirOrFiles);
            } else {
                // ä½¿ç”¨å·²åŠ è½½çš„æ•°æ®
                avatarDataFiles = this.avatarData;
            }

            if (!avatarDataFiles || Object.keys(avatarDataFiles).length === 0) {
                throw new Error('æ²¡æœ‰å¯ç”¨çš„ Avatar æ•°æ®');
            }

            // åŠ è½½èƒŒæ™¯è§†é¢‘å¸§
            try {
                if (avatarDataFiles['bg_video.mp4']) {
                    const bgVideoBlob = avatarDataFiles['bg_video.mp4'];
                    console.log('è§†é¢‘æ–‡ä»¶å¤§å°:', bgVideoBlob.size, 'bytes, ç±»å‹:', bgVideoBlob.type);
                    const bgVideoUrl = URL.createObjectURL(bgVideoBlob);
                    console.log('æ­£åœ¨æå–èƒŒæ™¯è§†é¢‘å¸§ï¼ŒURL:', bgVideoUrl.substring(0, 50) + '...');
                    try {
                        await this.extractVideoFrames(bgVideoUrl);
                        console.log(`âœ“ å·²æå– ${this.bgVideoFrames.length} ä¸ªèƒŒæ™¯å¸§`);
                    } finally {
                        URL.revokeObjectURL(bgVideoUrl);
                    }
                } else if (typeof dataDirOrFiles === 'string') {
                    // ä»è·¯å¾„åŠ è½½ï¼Œæ·»åŠ ç¼“å­˜ç ´åå‚æ•°
                    const videoPath = `${dataDirOrFiles}/bg_video.mp4?t=${Date.now()}`;
                    console.log('ä»è·¯å¾„åŠ è½½è§†é¢‘:', videoPath);
                    const bgVideoResponse = await fetch(videoPath, {
                        cache: 'no-cache'
                    });
                    if (!bgVideoResponse.ok) {
                        throw new Error(`æ— æ³•åŠ è½½è§†é¢‘æ–‡ä»¶: ${bgVideoResponse.status} ${bgVideoResponse.statusText}`);
                    }
                    const bgVideoBlob = await bgVideoResponse.blob();
                    console.log('è§†é¢‘æ–‡ä»¶å¤§å°:', bgVideoBlob.size, 'bytes, ç±»å‹:', bgVideoBlob.type);
                    const bgVideoUrl = URL.createObjectURL(bgVideoBlob);
                    console.log('æ­£åœ¨æå–èƒŒæ™¯è§†é¢‘å¸§...');
                    try {
                        await this.extractVideoFrames(bgVideoUrl);
                        console.log(`âœ“ å·²æå– ${this.bgVideoFrames.length} ä¸ªèƒŒæ™¯å¸§`);
                    } finally {
                        URL.revokeObjectURL(bgVideoUrl);
                    }
                } else {
                    throw new Error('æœªæ‰¾åˆ°èƒŒæ™¯è§†é¢‘æ–‡ä»¶ bg_video.mp4');
                }
            } catch (error) {
                console.error('æå–è§†é¢‘å¸§å¤±è´¥:', error);
                // è§†é¢‘è§£ç å¤±è´¥ï¼Œéœ€è¦ç”¨æˆ·å¤„ç†è§†é¢‘æ ¼å¼
                throw new Error(`èƒŒæ™¯è§†é¢‘è§£ç å¤±è´¥: ${error.message}ã€‚è¯·ç¡®ä¿è§†é¢‘æ ¼å¼ä¸ºæµè§ˆå™¨å…¼å®¹çš„ MP4/H.264 ç¼–ç ã€‚å¯ä»¥ä½¿ç”¨ ffmpeg è½¬æ¢: ffmpeg -i bg_video.mp4 -c:v libx264 -c:a aac -movflags +faststart bg_video_compatible.mp4`);
            }

            // åŠ è½½ neutral_pose
            if (avatarDataFiles['neutral_pose.npy']) {
                // éœ€è¦è§£æ .npy æ–‡ä»¶ï¼ˆå¯ä»¥ä½¿ç”¨ npyjs åº“ï¼‰
                console.log('neutral_pose.npy å·²åŠ è½½ï¼ˆéœ€è¦è§£æï¼‰');
            }

            // åŠ è½½ face_box
            let faceBoxText = null;
            if (avatarDataFiles['face_box.txt']) {
                faceBoxText = await avatarDataFiles['face_box.txt'].text();
            } else if (typeof dataDirOrFiles === 'string') {
                const faceBoxResponse = await fetch(`${dataDirOrFiles}/face_box.txt`);
                faceBoxText = await faceBoxResponse.text();
            }

            if (faceBoxText) {
                const [y1, y2, x1, x2] = faceBoxText.trim().split(/\s+/).map(Number);
                this.faceBox = { y1, y2, x1, x2 };
                console.log('face_box:', this.faceBox);

                // ç”Ÿæˆ merge_mask
                this.generateMergeMask();
            }

            // åŠ è½½å‚è€ƒå¸§
            await this.loadReferenceFrames(avatarDataFiles);
            
            // æ£€æŸ¥æ˜¯å¦æˆåŠŸåŠ è½½äº†èƒŒæ™¯è§†é¢‘å¸§ï¼ˆå¿…é¡»è¦æœ‰ bg_videoï¼‰
            if (!this.bgVideoFrames || this.bgVideoFrames.length === 0) {
                throw new Error('æœªèƒ½åŠ è½½èƒŒæ™¯è§†é¢‘å¸§ã€‚è¯·ç¡®ä¿ bg_video.mp4 æ–‡ä»¶å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®ï¼ˆMP4/H.264 ç¼–ç ï¼‰ã€‚\nå¦‚æœè§†é¢‘æ— æ³•è§£ç ï¼Œè¯·ä½¿ç”¨ convert_video.sh è„šæœ¬è½¬æ¢è§†é¢‘æ ¼å¼ã€‚');
            }
            
            console.log(`âœ“ æˆåŠŸåŠ è½½ ${this.bgVideoFrames.length} ä¸ªèƒŒæ™¯è§†é¢‘å¸§`);

            this.updateStatus('success', 'Avatar æ•°æ®å¤„ç†å®Œæˆ');
        } catch (error) {
            this.updateStatus('error', `å¤„ç† Avatar æ•°æ®å¤±è´¥: ${error.message}`);
            console.error('å¤„ç† Avatar æ•°æ®å¤±è´¥:', error);
            throw error;
        }
    }

    async extractVideoFrames(videoUrl) {
        return new Promise((resolve, reject) => {
            const video = document.createElement('video');
            video.preload = 'auto';
            video.muted = true;
            video.playsInline = true;
            
            // è®¾ç½®è¶…æ—¶
            const timeout = setTimeout(() => {
                reject(new Error('è§†é¢‘åŠ è½½è¶…æ—¶'));
            }, 30000); // 30ç§’è¶…æ—¶
            
            let isResolved = false;
            
            const cleanup = () => {
                if (isResolved) return;
                clearTimeout(timeout);
                video.removeEventListener('loadedmetadata', onLoadedMetadata);
                video.removeEventListener('loadeddata', onLoadedData);
                video.removeEventListener('error', onError);
                video.removeEventListener('canplay', onCanPlay);
                video.removeEventListener('canplaythrough', onCanPlayThrough);
            };
            
            const onLoadedMetadata = () => {
                console.log('è§†é¢‘å…ƒæ•°æ®åŠ è½½å®Œæˆ:', {
                    width: video.videoWidth,
                    height: video.videoHeight,
                    duration: video.duration,
                    readyState: video.readyState,
                    networkState: video.networkState
                });
                
                if (video.videoWidth === 0 || video.videoHeight === 0) {
                    cleanup();
                    if (!isResolved) {
                        isResolved = true;
                        reject(new Error('è§†é¢‘å°ºå¯¸æ— æ•ˆï¼ˆå®½é«˜ä¸º0ï¼‰'));
                    }
                }
            };
            
            const onError = (event) => {
                cleanup();
                if (isResolved) return;
                isResolved = true;
                
                const error = video.error;
                let errorMsg = 'è§†é¢‘è§£ç å¤±è´¥';
                
                console.error('è§†é¢‘å…ƒç´ é”™è¯¯:', {
                    error: error,
                    code: error?.code,
                    message: error?.message,
                    networkState: video.networkState,
                    readyState: video.readyState,
                    src: video.src.substring(0, 100)
                });
                
                if (error) {
                    switch (error.code) {
                        case error.MEDIA_ERR_ABORTED:
                            errorMsg = 'è§†é¢‘åŠ è½½è¢«ä¸­æ­¢';
                            break;
                        case error.MEDIA_ERR_NETWORK:
                            errorMsg = 'ç½‘ç»œé”™è¯¯å¯¼è‡´è§†é¢‘åŠ è½½å¤±è´¥';
                            break;
                        case error.MEDIA_ERR_DECODE:
                            errorMsg = 'è§†é¢‘è§£ç å¤±è´¥ã€‚æ–‡ä»¶å¯èƒ½æŸåæˆ–æ ¼å¼ä¸æ”¯æŒ';
                            break;
                        case error.MEDIA_ERR_SRC_NOT_SUPPORTED:
                            errorMsg = 'è§†é¢‘æ ¼å¼ä¸æ”¯æŒ';
                            break;
                        default:
                            errorMsg = error.message || `é”™è¯¯ä»£ç : ${error.code}`;
                    }
                }
                
                reject(new Error(`èƒŒæ™¯è§†é¢‘è§£ç å¤±è´¥: ${errorMsg}ã€‚è¯·æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦æ­£ç¡®è½¬æ¢`));
            };
            
            const onCanPlay = () => {
                console.log('è§†é¢‘å¯ä»¥æ’­æ”¾ï¼Œå°ºå¯¸:', video.videoWidth, 'x', video.videoHeight, 'readyState:', video.readyState);
            };
            
            const onCanPlayThrough = () => {
                console.log('è§†é¢‘å¯ä»¥å®Œæ•´æ’­æ”¾');
            };
            
            const onLoadedData = async () => {
                if (isResolved) return;
                
                try {
                    console.log('è§†é¢‘æ•°æ®åŠ è½½å®Œæˆï¼Œå¼€å§‹æå–å¸§...');
                    console.log('è§†é¢‘ä¿¡æ¯:', {
                        width: video.videoWidth,
                        height: video.videoHeight,
                        duration: video.duration,
                        readyState: video.readyState
                    });
                    
                    // ç­‰å¾…è§†é¢‘å®Œå…¨å‡†å¤‡å¥½
                    if (video.readyState < 3) {
                        console.log('ç­‰å¾…è§†é¢‘å‡†å¤‡å°±ç»ª...');
                        await new Promise((resolveReady) => {
                            const checkReady = () => {
                                if (video.readyState >= 3) {
                                    resolveReady();
                                } else {
                                    setTimeout(checkReady, 100);
                                }
                            };
                            checkReady();
                        });
                    }
                    
                    cleanup();
                    clearTimeout(timeout);
                    
                    if (video.videoWidth === 0 || video.videoHeight === 0) {
                        if (!isResolved) {
                            isResolved = true;
                            reject(new Error('è§†é¢‘å°ºå¯¸æ— æ•ˆï¼ˆå®½é«˜ä¸º0ï¼‰'));
                        }
                        return;
                    }
                    
                    // åˆå§‹åŒ– canvas
                    const canvas = document.createElement('canvas');
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    const ctx = canvas.getContext('2d');
                    
                    console.log('å¼€å§‹æå–è§†é¢‘å¸§ï¼Œæ€»æ—¶é•¿:', video.duration, 'ç§’');
                    
                    const frameRate = 30;
                    const frameInterval = 1 / frameRate;
                    const maxFrames = 150; // é™åˆ¶å¸§æ•°
                    const duration = Math.min(video.duration, maxFrames / frameRate);
                    const frames = [];
                    
                    const extractFrame = (time) => {
                        return new Promise((resolveFrame) => {
                            const seekTimeout = setTimeout(() => {
                                console.warn(`å¸§æå–è¶…æ—¶ (æ—¶é—´: ${time.toFixed(2)}s)`);
                                resolveFrame(null);
                            }, 3000);
                            
                            const onSeeked = () => {
                                clearTimeout(seekTimeout);
                                try {
                                    ctx.drawImage(video, 0, 0);
                                    const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
                                    resolveFrame(imageData);
                                } catch (error) {
                                    console.error('æå–å¸§æ—¶å‡ºé”™:', error);
                                    resolveFrame(null);
                                }
                            };
                            
                            video.addEventListener('seeked', onSeeked, { once: true });
                            video.currentTime = time;
                        });
                    };
                    
                    // æå–å¸§
                    for (let currentTime = 0; currentTime < duration && frames.length < maxFrames; currentTime += frameInterval) {
                        const frame = await extractFrame(currentTime);
                        if (frame) {
                            frames.push(frame);
                        }
                        // æ›´æ–°è¿›åº¦
                        if (frames.length % 10 === 0) {
                            console.log(`å·²æå– ${frames.length} å¸§...`);
                        }
                    }
                    
                    if (frames.length === 0) {
                        if (!isResolved) {
                            isResolved = true;
                            reject(new Error('æœªèƒ½æå–ä»»ä½•è§†é¢‘å¸§'));
                        }
                        return;
                    }
                    
                    console.log(`âœ“ æˆåŠŸæå– ${frames.length} ä¸ªè§†é¢‘å¸§`);
                    this.bgVideoFrames = frames;
                    if (!isResolved) {
                        isResolved = true;
                        resolve(frames);
                    }
                } catch (error) {
                    if (!isResolved) {
                        isResolved = true;
                        reject(error);
                    }
                }
            };
            
            video.addEventListener('loadedmetadata', onLoadedMetadata);
            video.addEventListener('loadeddata', onLoadedData);
            video.addEventListener('error', onError);
            video.addEventListener('canplay', onCanPlay);
            video.addEventListener('canplaythrough', onCanPlayThrough);
            
            // è®¾ç½®è§†é¢‘æº
            console.log('è®¾ç½®è§†é¢‘æº:', videoUrl);
            video.src = videoUrl;
            
            // å°è¯•åŠ è½½
            video.load();
            
            // æ·»åŠ é¢å¤–çš„é”™è¯¯æ£€æŸ¥
            setTimeout(() => {
                if (!isResolved && video.readyState === 0) {
                    console.error('è§†é¢‘åŠ è½½è¶…æ—¶ï¼ŒreadyState:', video.readyState);
                    if (video.error) {
                        onError(new Event('error'));
                    }
                }
            }, 5000);
        });
    }

    generateMergeMask() {
        if (!this.faceBox) return;

        const { y1, y2, x1, x2 } = this.faceBox;
        const width = x2 - x1;
        const height = y2 - y1;

        // åˆ›å»ºæ¸å˜é®ç½©
        const canvas = document.createElement('canvas');
        canvas.width = width;
        canvas.height = height;
        const ctx = canvas.getContext('2d');

        // ç»˜åˆ¶ç™½è‰²èƒŒæ™¯
        ctx.fillStyle = 'white';
        ctx.fillRect(0, 0, width, height);

        // ç»˜åˆ¶é»‘è‰²ä¸­å¿ƒåŒºåŸŸï¼ˆè¾¹ç¼˜ç•™ 10pxï¼‰
        ctx.fillStyle = 'black';
        ctx.fillRect(10, 10, width - 20, height - 20);

        // åº”ç”¨é«˜æ–¯æ¨¡ç³Šï¼ˆä½¿ç”¨ Canvas çš„ filterï¼Œæˆ–ä½¿ç”¨ WebGLï¼‰
        ctx.filter = 'blur(15px)';
        ctx.drawImage(canvas, 0, 0);

        const imageData = ctx.getImageData(0, 0, width, height);
        this.mergeMask = new Float32Array(imageData.data.length / 4);
        for (let i = 0; i < imageData.data.length; i += 4) {
            this.mergeMask[i / 4] = imageData.data[i] / 255;
        }
    }

    async loadReferenceFrames(dataDirOrFiles) {
        // ä»å·²åŠ è½½çš„æ•°æ®ä¸­æå–å‚è€ƒå¸§
        const refFrames = [];
        
        // å¦‚æœä¼ å…¥çš„æ˜¯æ–‡ä»¶å¯¹è±¡å­—å…¸
        if (typeof dataDirOrFiles === 'object' && !Array.isArray(dataDirOrFiles)) {
            const refFrameKeys = Object.keys(dataDirOrFiles)
                .filter(key => key.startsWith('ref_frames/') || key.match(/^ref_\d+\.jpg$/))
                .sort();

            for (const key of refFrameKeys) {
                const file = dataDirOrFiles[key];
                if (file instanceof File || file instanceof Blob) {
                    const imageUrl = URL.createObjectURL(file);
                    refFrames.push({
                        key: key,
                        file: file,
                        url: imageUrl
                    });
                }
            }
        } else if (typeof dataDirOrFiles === 'string') {
            // ä»è·¯å¾„åŠ è½½ï¼ˆéœ€è¦å®ç°ï¼‰
            console.log('ä»è·¯å¾„åŠ è½½å‚è€ƒå¸§åŠŸèƒ½å¾…å®ç°');
        }

        this.refFrames = refFrames;
        console.log(`å·²åŠ è½½ ${refFrames.length} ä¸ªå‚è€ƒå¸§`);
    }

    async processAudio(audioFile, targetFrameCount = null) {
        this.updateStatus('', 'æ­£åœ¨å¤„ç†éŸ³é¢‘...');
        
        try {
            // è¯»å–éŸ³é¢‘æ–‡ä»¶
            const arrayBuffer = await audioFile.arrayBuffer();
            const inputAudioBuffer = await this.decodeAudioData(arrayBuffer);

            // ç›®æ ‡æ ¼å¼ï¼š16kHz, å•å£°é“
            const targetSampleRate = 16000;
            const targetChannels = 1;
            
            // ç¡®ä¿ audioContext å·²åˆå§‹åŒ–
            if (!this.audioContext) {
                this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
            }
            
            // åˆ›å»ºç›®æ ‡ AudioContextï¼ˆ16kHzï¼‰
            const targetAudioContext = new (window.AudioContext || window.webkitAudioContext)({
                sampleRate: targetSampleRate
            });
            
            // 1. é‡é‡‡æ ·åˆ° 16kHzï¼ˆå¦‚æœéœ€è¦ï¼‰
            let processedBuffer = inputAudioBuffer;
            if (inputAudioBuffer.sampleRate !== targetSampleRate) {
                console.log(`é‡é‡‡æ ·éŸ³é¢‘: ${inputAudioBuffer.sampleRate}Hz -> ${targetSampleRate}Hz`);
                processedBuffer = await this.resampleAudioBuffer(inputAudioBuffer, targetSampleRate);
            }
            
            // 2. è½¬æ¢ä¸ºå•å£°é“ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if (processedBuffer.numberOfChannels !== targetChannels) {
                console.log(`è½¬æ¢éŸ³é¢‘é€šé“: ${processedBuffer.numberOfChannels} -> ${targetChannels}`);
                processedBuffer = await this.convertToMono(processedBuffer);
            }
            
            // 3. ä¿å­˜å¤„ç†åçš„éŸ³é¢‘ç¼“å†²åŒºï¼ˆç”¨äºåç»­è§†é¢‘åˆæˆï¼‰
            this.processedAudioBuffer = processedBuffer;
            
            // 4. æå–éŸ³é¢‘æ•°æ®ç”¨äºç‰¹å¾æå–
            const audioData = processedBuffer.getChannelData(0);
            
            // 5. ç¡®å®šç›®æ ‡å¸§æ•°
            // å¦‚æœæŒ‡å®šäº† targetFrameCountï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™åŸºäºéŸ³é¢‘æ—¶é•¿è®¡ç®—
            const fps = 30;
            const frameCount = targetFrameCount !== null 
                ? targetFrameCount 
                : Math.floor(audioData.length / targetSampleRate * fps);
            
            console.log('éŸ³é¢‘å¤„ç†:', {
                åŸå§‹é‡‡æ ·ç‡: inputAudioBuffer.sampleRate,
                ç›®æ ‡é‡‡æ ·ç‡: targetSampleRate,
                éŸ³é¢‘æ—¶é•¿: processedBuffer.duration.toFixed(2) + 'ç§’',
                éŸ³é¢‘é‡‡æ ·æ•°: audioData.length,
                ç›®æ ‡å¸§æ•°: frameCount,
                åŸºäº: targetFrameCount !== null ? 'è§†é¢‘å¸§æ•°' : 'éŸ³é¢‘æ—¶é•¿'
            });
            
            // 6. æå–éŸ³é¢‘ç‰¹å¾
            const audioFeatures = await this.extractAudioFeatures(audioData, frameCount);

            // 6. ä½¿ç”¨ audio2mouth æ¨¡å‹ç”Ÿæˆå˜´éƒ¨å‚æ•°
            const mouthParams = await this.audio2mouthInference(audioFeatures, frameCount);
            
            console.log('éŸ³é¢‘å¤„ç†å®Œæˆ:', {
                åŸå§‹é‡‡æ ·ç‡: inputAudioBuffer.sampleRate,
                ç›®æ ‡é‡‡æ ·ç‡: targetSampleRate,
                åŸå§‹é€šé“æ•°: inputAudioBuffer.numberOfChannels,
                ç›®æ ‡é€šé“æ•°: targetChannels,
                æ—¶é•¿: processedBuffer.duration.toFixed(2) + 'ç§’',
                é‡‡æ ·æ•°: processedBuffer.length
            });

            return mouthParams;
        } catch (error) {
            this.updateStatus('error', `éŸ³é¢‘å¤„ç†å¤±è´¥: ${error.message}`);
            throw error;
        }
    }

    async decodeAudioData(arrayBuffer) {
        if (!this.audioContext) {
            this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
        }
        return await this.audioContext.decodeAudioData(arrayBuffer);
    }

    resampleAudio(audioData, fromRate, toRate) {
        // ç®€å•çš„çº¿æ€§æ’å€¼é‡é‡‡æ ·
        const ratio = fromRate / toRate;
        const newLength = Math.floor(audioData.length / ratio);
        const resampled = new Float32Array(newLength);

        for (let i = 0; i < newLength; i++) {
            const srcIndex = i * ratio;
            const index = Math.floor(srcIndex);
            const fraction = srcIndex - index;
            
            if (index + 1 < audioData.length) {
                resampled[i] = audioData[index] * (1 - fraction) + audioData[index + 1] * fraction;
            } else {
                resampled[i] = audioData[index];
            }
        }

        return resampled;
    }
    
    async resampleAudioBuffer(audioBuffer, targetSampleRate) {
        const sourceSampleRate = audioBuffer.sampleRate;
        const numberOfChannels = audioBuffer.numberOfChannels;
        const length = audioBuffer.length;
        const targetLength = Math.round(length * targetSampleRate / sourceSampleRate);
        
        // åˆ›å»ºæ–°çš„ AudioContext ç”¨äºé‡é‡‡æ ·
        const offlineContext = new OfflineAudioContext(
            numberOfChannels,
            targetLength,
            targetSampleRate
        );
        
        // åˆ›å»ºæºèŠ‚ç‚¹
        const source = offlineContext.createBufferSource();
        source.buffer = audioBuffer;
        source.connect(offlineContext.destination);
        source.start(0);
        
        // æ¸²æŸ“å¹¶è¿”å›é‡é‡‡æ ·åçš„ buffer
        return await offlineContext.startRendering();
    }
    
    async convertToMono(audioBuffer) {
        if (audioBuffer.numberOfChannels === 1) {
            return audioBuffer;
        }
        
        const numberOfChannels = audioBuffer.numberOfChannels;
        const length = audioBuffer.length;
        const sampleRate = audioBuffer.sampleRate;
        
        // ç¡®ä¿æœ‰ audioContext
        if (!this.audioContext) {
            this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
        }
        
        // åˆ›å»ºå•å£°é“ buffer
        const monoBuffer = this.audioContext.createBuffer(1, length, sampleRate);
        const monoData = monoBuffer.getChannelData(0);
        
        // æ··åˆæ‰€æœ‰é€šé“
        for (let i = 0; i < numberOfChannels; i++) {
            const channelData = audioBuffer.getChannelData(i);
            for (let j = 0; j < length; j++) {
                monoData[j] += channelData[j] / numberOfChannels;
            }
        }
        
        return monoBuffer;
    }

    // ï¼ˆå·²ç§»é™¤ï¼‰å‰ç«¯ Mel/FFT/LFR ç‰¹å¾æå–é€»è¾‘ï¼šç‰¹å¾ç»Ÿä¸€èµ°åç«¯ `/extract_features`
    
    // ï¼ˆå·²ç§»é™¤ï¼‰createMelFilterBank / FFT ç­‰å‰ç«¯ç‰¹å¾æå–è¾…åŠ©å‡½æ•°
    
    // ï¼ˆå·²ç§»é™¤ï¼‰å‰ç«¯ LFR/æ’å€¼é€»è¾‘ï¼šç‰¹å¾ç»Ÿä¸€èµ°åç«¯ `/extract_features`

    async extractAudioFeatures(audioData, frameCount) {
        // å…¨å‰ç«¯æ¨¡å¼ï¼šä½¿ç”¨æµè§ˆå™¨ç«¯ Paraformer æ¨¡å‹
        console.log('æ£€æŸ¥å‰ç«¯ç‰¹å¾æå–æ¡ä»¶:', {
            useFrontendFeatureExtraction: this.useFrontendFeatureExtraction,
            hasParaformerModel: !!this.paraformerModel,
            hasFrontend: !!this.frontend
        });
        
        // å…¨å‰ç«¯æ¨¡å¼ï¼šä½¿ç”¨æµè§ˆå™¨ç«¯ Paraformer æ¨¡å‹
        if (this.useFrontendFeatureExtraction && this.paraformerModel && this.frontend) {
            console.log('ä½¿ç”¨å‰ç«¯ Paraformer æ¨¡å‹æå–ç‰¹å¾');
            return await this.extractFeaturesFromFrontend(audioData, frameCount);
        }
        
        // å¦‚æœå‰ç«¯ç‰¹å¾æå–ä¸å¯ç”¨ï¼Œç›´æ¥æŠ¥é”™ï¼ˆä¸å†æ”¯æŒåç«¯å›é€€ï¼‰
        throw new Error('å‰ç«¯ç‰¹å¾æå–ä¸å¯ç”¨ã€‚è¯·ç¡®ä¿ Paraformer æ¨¡å‹å·²æ­£ç¡®åŠ è½½ã€‚');
        
        if (this.featureExtractor) {
            try {
                // å°è¯•ä½¿ç”¨å®Œæ•´çš„ç‰¹å¾æå–å™¨
                const features = await this.featureExtractor.extractFeatures(audioData, frameCount);
                console.log(`ç‰¹å¾æå–å™¨è¿”å›ç‰¹å¾é•¿åº¦: ${features.length}, æœŸæœ›: ${frameCount * numChannels * featureDim}`);
                
                // å¦‚æœè¿”å›çš„æ˜¯ [time * features] æ ¼å¼ï¼Œéœ€è¦è½¬æ¢ä¸º [time * channels * features]
                if (features.length === frameCount * featureDim) {
                    // æ‰©å±•ä¸ºå¤šé€šé“æ ¼å¼ï¼šå°†å•é€šé“ç‰¹å¾å¤åˆ¶åˆ°æ‰€æœ‰é€šé“
                    const multiChannelFeatures = new Float32Array(frameCount * numChannels * featureDim);
                    for (let t = 0; t < frameCount; t++) {
                        for (let c = 0; c < numChannels; c++) {
                            const srcStart = t * featureDim;
                            const dstStart = (t * numChannels * featureDim) + (c * featureDim);
                            multiChannelFeatures.set(
                                features.slice(srcStart, srcStart + featureDim),
                                dstStart
                            );
                        }
                    }
                    console.log(`ç‰¹å¾å·²æ‰©å±•ä¸ºå¤šé€šé“æ ¼å¼ï¼Œé•¿åº¦: ${multiChannelFeatures.length}`);
                    return multiChannelFeatures;
                } else if (features.length < frameCount * numChannels * featureDim) {
                    // ç‰¹å¾æ•°é‡ä¸è¶³ï¼Œéœ€è¦æ’å€¼æˆ–å¡«å……
                    console.warn(`ç‰¹å¾æ•°é‡ä¸è¶³: å®é™… ${features.length}, æœŸæœ› ${frameCount * numChannels * featureDim}`);
                    // æ£€æŸ¥æ˜¯å¦æ˜¯ [time * features] æ ¼å¼
                    const actualFrames = features.length / featureDim;
                    if (actualFrames > 0 && actualFrames < frameCount) {
                        // éœ€è¦æ’å€¼åˆ°ç›®æ ‡å¸§æ•°
                        const interpolatedFeatures = new Float32Array(frameCount * numChannels * featureDim);
                        for (let t = 0; t < frameCount; t++) {
                            const srcFrameIdx = Math.floor((t / frameCount) * actualFrames);
                            const srcStart = srcFrameIdx * featureDim;
                            for (let c = 0; c < numChannels; c++) {
                                const dstStart = (t * numChannels * featureDim) + (c * featureDim);
                                if (srcStart + featureDim <= features.length) {
                                    interpolatedFeatures.set(
                                        features.slice(srcStart, srcStart + featureDim),
                                        dstStart
                                    );
                                }
                            }
                        }
                        console.log(`ç‰¹å¾å·²æ’å€¼ï¼Œé•¿åº¦: ${interpolatedFeatures.length}`);
                        return interpolatedFeatures;
                    }
                }
                // å¦‚æœæ ¼å¼æ­£ç¡®ï¼Œç›´æ¥è¿”å›
                if (features.length === frameCount * numChannels * featureDim) {
                    return features;
                }
                console.warn(`ç‰¹å¾æ ¼å¼ä¸åŒ¹é…ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬`);
            } catch (error) {
                console.warn('ç‰¹å¾æå–å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬:', error);
            }
        }
        
        // ä½¿ç”¨æ”¹è¿›çš„ç‰¹å¾æå–ï¼šåŸºäºçœŸå®çš„ Mel é¢‘è°± + LFR
        // è¿™æ¯”å®Œå…¨éšæœºæ›´æ¥è¿‘çœŸå®ç‰¹å¾
        console.log('ä½¿ç”¨æ”¹è¿›çš„ç‰¹å¾æå–ï¼ˆåŸºäº Mel é¢‘è°±ï¼‰...');
        
        // 1. æå– Mel é¢‘è°±ç‰¹å¾ï¼ˆä½¿ç”¨ Web Audio APIï¼‰
        const melFeatures = await this.extractMelSpectrogramImproved(audioData, frameCount);
        
        // 2. æ‰©å±•ä¸º 30 é€šé“æ ¼å¼
        // Paraformer encoder æœ‰ 30 å±‚ï¼Œæ¯å±‚è¾“å‡º 512 ç»´ç‰¹å¾
        // æˆ‘ä»¬éœ€è¦å°† Mel ç‰¹å¾ï¼ˆ560ç»´ï¼‰æ˜ å°„åˆ° 512 ç»´ï¼Œç„¶åä¸ºæ¯ä¸ªé€šé“ç”Ÿæˆä¸åŒçš„è¡¨ç¤º
        const totalLength = frameCount * numChannels * featureDim;
        const features = new Float32Array(totalLength);
        
        // Mel ç‰¹å¾ç»´åº¦ï¼ˆLFR åï¼‰
        const melFeatureDim = 560; // LFR: 80 * 7 = 560
        
        // è®¡ç®—ç‰¹å¾çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆç”¨äºå½’ä¸€åŒ–ï¼‰
        let melMin = Infinity, melMax = -Infinity, melSum = 0, melCount = 0;
        for (let i = 0; i < melFeatures.length; i++) {
            const val = melFeatures[i];
            if (isFinite(val)) {
                melMin = Math.min(melMin, val);
                melMax = Math.max(melMax, val);
                melSum += val;
                melCount++;
            }
        }
        const melMean = melSum / melCount;
        const melStd = Math.sqrt(melFeatures.reduce((sum, val) => {
            if (isFinite(val)) {
                return sum + Math.pow(val - melMean, 2);
            }
            return sum;
        }, 0) / melCount);
        
        console.log('Mel ç‰¹å¾ç»Ÿè®¡:', {
            æœ€å°å€¼: melMin.toFixed(3),
            æœ€å¤§å€¼: melMax.toFixed(3),
            å¹³å‡å€¼: melMean.toFixed(3),
            æ ‡å‡†å·®: melStd.toFixed(3)
        });
        
        // ä¸ºæ¯ä¸ªé€šé“åˆ›å»ºä¸åŒçš„çº¿æ€§å˜æ¢çŸ©é˜µï¼ˆæ¨¡æ‹Ÿ encoder çš„ä¸åŒå±‚ï¼‰
        // ä½¿ç”¨æ›´åˆç†çš„æŠ•å½±çŸ©é˜µå°† 560 ç»´æ˜ å°„åˆ° 512 ç»´
        // ä½¿ç”¨ PCA é£æ ¼çš„æŠ•å½±ï¼šå°† Mel ç‰¹å¾çš„ä¸»è¦æˆåˆ†æ˜ å°„åˆ° 512 ç»´
        const projectionMatrices = [];
        for (let c = 0; c < numChannels; c++) {
            const matrix = new Float32Array(melFeatureDim * featureDim);
            // ä½¿ç”¨æ›´åˆç†çš„æƒé‡åˆå§‹åŒ–ï¼ˆç±»ä¼¼ Xavier/Glorot åˆå§‹åŒ–ï¼‰
            const scale = Math.sqrt(2.0 / (melFeatureDim + featureDim));
            const seed = c * 12345;
            
            // ä½¿ç”¨ä¼ªéšæœºæ•°ç”Ÿæˆå™¨ï¼ˆåŸºäºé€šé“ç´¢å¼•ï¼‰
            let rng = seed;
            const random = () => {
                rng = (rng * 1103515245 + 12345) & 0x7fffffff;
                return (rng / 0x7fffffff) * 2 - 1; // -1 åˆ° 1
            };
            
            for (let i = 0; i < matrix.length; i++) {
                // ä½¿ç”¨æ­£æ€åˆ†å¸ƒé£æ ¼çš„æƒé‡
                matrix[i] = random() * scale;
            }
            projectionMatrices.push(matrix);
        }
        
        for (let t = 0; t < frameCount; t++) {
            const melStart = t * melFeatureDim;
            const melFrame = new Float32Array(melFeatureDim);
            for (let i = 0; i < melFeatureDim; i++) {
                if (melStart + i < melFeatures.length) {
                    melFrame[i] = melFeatures[melStart + i];
                }
            }
            
            // å½’ä¸€åŒ– Mel ç‰¹å¾ï¼ˆZ-score normalizationï¼‰
            for (let i = 0; i < melFeatureDim; i++) {
                if (melStd > 0) {
                    melFrame[i] = (melFrame[i] - melMean) / melStd;
                }
            }
            
            // ä¸ºæ¯ä¸ªé€šé“ç”Ÿæˆç‰¹å¾
            for (let c = 0; c < numChannels; c++) {
                const baseIdx = (t * numChannels * featureDim) + (c * featureDim);
                const matrix = projectionMatrices[c];
                
                // çŸ©é˜µä¹˜æ³•ï¼šmelFrame (560) x matrix (560x512) -> output (512)
                for (let f = 0; f < featureDim; f++) {
                    let sum = 0;
                    for (let m = 0; m < melFeatureDim; m++) {
                        sum += melFrame[m] * matrix[m * featureDim + f];
                    }
                    // æ·»åŠ é€šé“ç‰¹å®šçš„åç½®å’Œæ¿€æ´»
                    const bias = Math.sin((c / numChannels) * Math.PI * 2) * 0.01;
                    features[baseIdx + f] = sum + bias;
                }
            }
        }
        
        // æ£€æŸ¥ç‰¹å¾å€¼èŒƒå›´
        let minVal = Infinity, maxVal = -Infinity;
        let validCount = 0;
        for (let i = 0; i < features.length; i++) {
            const val = features[i];
            if (isFinite(val) && !isNaN(val)) {
                if (val < minVal) minVal = val;
                if (val > maxVal) maxVal = val;
                validCount++;
            }
        }
        
        if (validCount === 0) {
            console.warn('è­¦å‘Šï¼šç‰¹å¾æ•°ç»„ä¸­æ²¡æœ‰æœ‰æ•ˆå€¼ï¼');
            // å¡«å……ä¸€äº›é»˜è®¤å€¼ä»¥é¿å…å…¨é›¶
            for (let i = 0; i < features.length; i++) {
                features[i] = (Math.random() - 0.5) * 0.1;
            }
            minVal = -0.05;
            maxVal = 0.05;
        }
        
        console.log('ç‰¹å¾æ•°ç»„åˆ›å»ºå®Œæˆï¼Œå®é™…é•¿åº¦:', features.length, 'æœ‰æ•ˆå€¼:', validCount, 'å€¼èŒƒå›´:', minVal.toFixed(3), 'åˆ°', maxVal.toFixed(3));
        return features;
    }
    
    /**
     * å‰ç«¯ç‰¹å¾æå–ï¼šä½¿ç”¨ Paraformer ONNX æ¨¡å‹
     */
    async extractFeaturesFromFrontend(audioData, frameCount) {
        console.log('ä½¿ç”¨å‰ç«¯ Paraformer æ¨¡å‹æå–ç‰¹å¾...');
        
        // 1. å‰ç«¯ç‰¹å¾æå–ï¼ˆfbank + LFR + CMVNï¼‰
        const frontendResult = this.frontend.process(audioData);
        let feats = frontendResult.features; // [T * D] æ ¼å¼
        let numFrames = frontendResult.numFrames;
        const featDim = frontendResult.featDim; // åº”è¯¥æ˜¯ 560 (80 * 7)
        
        // 2. å›ºå®šè¾“å…¥é•¿åº¦ä¸º 150 å¸§ï¼ˆæ¨¡å‹å¯¼å‡ºæ—¶çš„å›ºå®šå¤§å°ï¼‰
        // NOTE: Paraformer ONNX model has hardcoded attention mask for 150 frames
        const FIXED_TIME_DIM = 150;
        
        if (numFrames > FIXED_TIME_DIM) {
            // æˆªæ–­åˆ° 150 å¸§
            console.warn(`è¾“å…¥é•¿åº¦ ${numFrames} è¶…è¿‡æ¨¡å‹é™åˆ¶ ${FIXED_TIME_DIM}ï¼Œå°†æˆªæ–­`);
            feats = feats.slice(0, FIXED_TIME_DIM * featDim);
            numFrames = FIXED_TIME_DIM;
        } else if (numFrames < FIXED_TIME_DIM) {
            // å¡«å……åˆ° 150 å¸§ï¼ˆä½¿ç”¨æœ€åä¸€å¸§çš„å€¼ï¼‰
            console.warn(`è¾“å…¥é•¿åº¦ ${numFrames} å°äºæ¨¡å‹è¦æ±‚ ${FIXED_TIME_DIM}ï¼Œå°†å¡«å……`);
            const lastFrame = feats.slice(-featDim);
            const paddingFrames = FIXED_TIME_DIM - numFrames;
            const padding = new Float32Array(paddingFrames * featDim);
            for (let i = 0; i < paddingFrames; i++) {
                padding.set(lastFrame, i * featDim);
            }
            feats = new Float32Array([...feats, ...padding]);
            numFrames = FIXED_TIME_DIM;
        }
        
        console.log('å‰ç«¯ç‰¹å¾æå–å®Œæˆ:', {
            originalFrames: frontendResult.numFrames,
            adjustedFrames: numFrames,
            featDim: featDim,
            totalLength: feats.length
        });
        
        // 3. å‡†å¤‡ ONNX æ¨¡å‹è¾“å…¥
        // è¾“å…¥æ ¼å¼ï¼š[B, T, D] = [1, 150, 560]
        const featsTensor = new ort.Tensor('float32', feats, [1, numFrames, featDim]);
        console.log('å‡†å¤‡ ONNX è¾“å…¥:', {
            featsShape: [1, numFrames, featDim],
            featsSize: feats.length,
            numFrames: numFrames
        });

        // 3. è¿è¡Œ ONNX æ¨¡å‹
        const feeds = {};
        const inputNames = this.paraformerModel.inputNames || [];
        console.log('Paraformer æ¨¡å‹è¾“å…¥åç§°:', inputNames);
        
        // å‡†å¤‡ feats_lengths å¼ é‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
        const featsLengthsI32 = new ort.Tensor('int32', new Int32Array([numFrames]), [1]);
        const featsLengthsI64 = new ort.Tensor('int64', new BigInt64Array([BigInt(numFrames)]), [1]);
        
        // æ ¹æ®è¾“å…¥åç§°åŒ¹é…è¾“å…¥
        if (inputNames.length === 1) {
            // åªæœ‰ä¸€ä¸ªè¾“å…¥ï¼Œåº”è¯¥æ˜¯ feats
            feeds[inputNames[0]] = featsTensor;
            console.log('ä½¿ç”¨å•è¾“å…¥æ¨¡å¼:', inputNames[0]);
        } else if (inputNames.length >= 2) {
            // ä¸¤ä¸ªè¾“å…¥ï¼šfeats å’Œ feats_lengths
            const name0 = inputNames[0];
            const name1 = inputNames[1];
            
            // åˆ¤æ–­å“ªä¸ªæ˜¯ featsï¼Œå“ªä¸ªæ˜¯ lengths
            if (String(name0).toLowerCase().includes('len') || String(name0).toLowerCase().includes('length')) {
                feeds[name0] = featsLengthsI32;
                feeds[name1] = featsTensor;
                console.log('ä½¿ç”¨åŒè¾“å…¥æ¨¡å¼ (lengths first):', { [name0]: 'int32[1]', [name1]: 'float32[1,T,D]' });
            } else if (String(name1).toLowerCase().includes('len') || String(name1).toLowerCase().includes('length')) {
                feeds[name0] = featsTensor;
                feeds[name1] = featsLengthsI32;
                console.log('ä½¿ç”¨åŒè¾“å…¥æ¨¡å¼ (feats first):', { [name0]: 'float32[1,T,D]', [name1]: 'int32[1]' });
                } else {
                // é»˜è®¤ï¼šç¬¬ä¸€ä¸ªæ˜¯ featsï¼Œç¬¬äºŒä¸ªæ˜¯ lengths
                feeds[name0] = featsTensor;
                feeds[name1] = featsLengthsI32;
                console.log('ä½¿ç”¨åŒè¾“å…¥æ¨¡å¼ (é»˜è®¤é¡ºåº):', { [name0]: 'float32[1,T,D]', [name1]: 'int32[1]' });
            }
        } else {
            // æç«¯é˜²å¾¡æ€§å›é€€ï¼šå‡è®¾è¾“å…¥åç§°æ˜¯ 'feats'
            feeds.feats = featsTensor;
            console.warn('æœªæ£€æµ‹åˆ°è¾“å…¥åç§°ï¼Œä½¿ç”¨é»˜è®¤åç§° "feats"');
        }

        // 4. è¿è¡Œæ¨ç†ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        let results;
        try {
            console.log('å¼€å§‹ Paraformer æ¨ç†ï¼Œè¾“å…¥:', Object.keys(feeds));
            // æ‰“å°è¾“å…¥å¼ é‡çš„è¯¦ç»†ä¿¡æ¯
            for (const [name, tensor] of Object.entries(feeds)) {
                console.log(`  è¾“å…¥ ${name}: ç±»å‹=${tensor.type}, å½¢çŠ¶=[${tensor.dims.join(', ')}], å¤§å°=${tensor.size}`);
            }
            results = await this.paraformerModel.run(feeds);
            console.log('Paraformer æ¨ç†æˆåŠŸï¼Œè¾“å‡º:', Object.keys(results));
            // æ‰“å°è¾“å‡ºå¼ é‡çš„è¯¦ç»†ä¿¡æ¯
            for (const [name, tensor] of Object.entries(results)) {
                console.log(`  è¾“å‡º ${name}: ç±»å‹=${tensor.type}, å½¢çŠ¶=[${tensor.dims.join(', ')}], å¤§å°=${tensor.size}`);
            }
        } catch (e) {
            // æ‰“å°è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            console.error('Paraformer æ¨ç†å¤±è´¥ï¼Œè¯¦ç»†ä¿¡æ¯:');
            console.error('  é”™è¯¯ç±»å‹:', typeof e);
            console.error('  é”™è¯¯æ¶ˆæ¯:', e.message || String(e));
            console.error('  é”™è¯¯ä»£ç :', (typeof e === 'number') ? e : (e.code || 'N/A'));
            console.error('  è¾“å…¥ä¿¡æ¯:');
            for (const [name, tensor] of Object.entries(feeds)) {
                console.error(`    ${name}: ç±»å‹=${tensor.type}, å½¢çŠ¶=[${tensor.dims.join(', ')}], å¤§å°=${tensor.size}`);
            }
            
            // å¦‚æœæ˜¯åŒè¾“å…¥ä¸”å¤±è´¥ï¼Œå°è¯•ç”¨ int64 çš„ lengths é‡è¯•
            if (inputNames.length >= 2) {
                console.warn('ä½¿ç”¨ int32 lengths å¤±è´¥ï¼Œå°è¯• int64:', e.message);
                const retryFeeds = { ...feeds };
                for (const k of Object.keys(retryFeeds)) {
                    if (String(k).toLowerCase().includes('len') || String(k).toLowerCase().includes('length')) {
                        retryFeeds[k] = featsLengthsI64;
                        console.log('å°†', k, 'æ”¹ä¸º int64');
                    }
                }
                try {
                    results = await this.paraformerModel.run(retryFeeds);
                    console.log('ä½¿ç”¨ int64 lengths é‡è¯•æˆåŠŸ');
                } catch (e2) {
                    console.error('Paraformer æ¨ç†å¤±è´¥ (int64 é‡è¯•ä¹Ÿå¤±è´¥):', e2);
                    const normalized = (typeof e2 === 'number') ? new Error(`Paraformer run failed (code=${e2})`) : e2;
                    throw normalized;
                }
            } else {
                const normalized = (typeof e === 'number') ? new Error(`Paraformer run failed (code=${e})`) : e;
                throw normalized;
            }
        }

        const hidden = results.hidden; // [B, L, T, C] = [1, 50, T, 512]
        
        console.log('Paraformer æ¨¡å‹æ¨ç†å®Œæˆ:', {
            hiddenShape: hidden.dims,
            hiddenSize: hidden.size
        });
        
        // 4. ç›´æ¥åœ¨ hidden.data ä¸Šåšæ—¶é—´æ’å€¼ï¼Œé¿å…æ„é€ å¤§é‡ä¸­é—´æ•°ç»„å¯¼è‡´å†…å­˜çˆ†ç‚¸
        const hiddenData = hidden.data; // Float32Array
        const [B, L, T, C] = hidden.dims; // expected B=1, L=50, T=numFrames, C=512

        if (B !== 1) {
            throw new Error(`Unexpected batch size from paraformer hidden: B=${B}`);
        }
        if (C !== 512) {
            console.warn(`Unexpected hidden dim C=${C} (expected 512)`);
        }

        const outputFeatures = new Float32Array(frameCount * L * C); // [frameCount, L, C]

        // linear interpolation along time axis
        for (let tOut = 0; tOut < frameCount; tOut++) {
            const ratio = (frameCount === 1) ? 0 : (tOut / (frameCount - 1)) * (T - 1);
            const t0 = Math.floor(ratio);
            const t1 = Math.min(t0 + 1, T - 1);
            const a = ratio - t0;

            for (let l = 0; l < L; l++) {
                const base0 = (l * T * C) + (t0 * C);
                const base1 = (l * T * C) + (t1 * C);
                const outBase = (tOut * L * C) + (l * C);

                for (let c = 0; c < C; c++) {
                    const v0 = hiddenData[base0 + c];
                    const v1 = hiddenData[base1 + c];
                    outputFeatures[outBase + c] = v0 * (1 - a) + v1 * a;
                }
            }
        }
        
        console.log('å‰ç«¯ç‰¹å¾æå–å®Œæˆ:', {
            outputShape: [frameCount, L, C],
            outputLength: outputFeatures.length
        });
        
        return outputFeatures;
    }
    

    async audio2mouthInference(audioFeatures, frameCount) {
        if (!this.audio2mouthModel) {
            await this.initializeModels();
        }

        this.updateStatus('', 'æ­£åœ¨ç”Ÿæˆå˜´éƒ¨å‚æ•°...');

        const interval = 1.0;
        const frag = Math.floor(interval * 30 / 5 + 0.5);
        const paramRes = [];

        let startTime = 0.0;
        let endTime = startTime + interval;
        const audioLength = frameCount / 30;
        let isEnd = false;

        while (true) {
            let start = Math.floor(startTime * 16000);
            let end = start + 16000;

            if (endTime >= audioLength) {
                isEnd = true;
                end = Math.floor(audioLength * 16000);
                start = end - 16000;
                startTime = audioLength - interval;
                endTime = audioLength;
            }

            const startFrame = Math.floor(startTime * 30);
            // æ ¹æ® Python ä»£ç ï¼šend_frame = start_frame + int(30 * interval)ï¼Œå…¶ä¸­ interval=1.0
            // æ‰€ä»¥ input_au çš„æ—¶é—´ç»´åº¦æ˜¯ 50ï¼ˆæ¨¡å‹æœŸæœ›ï¼‰ï¼Œä½† input_ph çš„æ—¶é—´ç»´åº¦æ˜¯ 30
            const expectedTimeFramesAu = 50; // input_au çš„æ—¶é—´ç»´åº¦
            const expectedTimeFramesPh = 30; // input_ph çš„æ—¶é—´ç»´åº¦
            const numChannels = 30; // æ ¹æ®é”™è¯¯ä¿¡æ¯ï¼Œé€šé“æ•°åº”è¯¥æ˜¯ 30
            const featureDim = 512; // ç‰¹å¾ç»´åº¦
            
            // å‡†å¤‡è¾“å…¥: æ¨¡å‹æœŸæœ› [batch=1, channels=30, time=50, features=512]
            // éœ€è¦ä»ç‰¹å¾ä¸­æå–å¯¹åº”çš„æ—¶é—´å¸§å’Œé€šé“
            const inputAuData = new Float32Array(1 * numChannels * expectedTimeFramesAu * featureDim);
            
            // æ£€æŸ¥ç‰¹å¾æ•°ç»„é•¿åº¦
            // éœ€è¦çš„æ€»é•¿åº¦ = frameCount * numChannels * featureDim
            const expectedTotalLength = frameCount * numChannels * featureDim;
            const requiredLength = (startFrame + expectedTimeFramesAu) * numChannels * featureDim;
            
            console.log(`ç‰¹å¾æ•°ç»„æ£€æŸ¥: å®é™…é•¿åº¦=${audioFeatures.length}, æœŸæœ›æ€»é•¿åº¦=${expectedTotalLength}, å½“å‰çª—å£éœ€è¦=${requiredLength}, startFrame=${startFrame}, frameCount=${frameCount}`);
            
            // å¦‚æœç‰¹å¾æ•°ç»„é•¿åº¦ä¸è¶³ï¼Œéœ€è¦æ‰©å±•
            if (audioFeatures.length < expectedTotalLength) {
                console.warn(`ç‰¹å¾æ•°ç»„é•¿åº¦ä¸è¶³ï¼Œæ‰©å±•ä¸­: å®é™… ${audioFeatures.length}, æœŸæœ› ${expectedTotalLength}`);
                const expandedFeatures = new Float32Array(expectedTotalLength);
                // å¤åˆ¶ç°æœ‰ç‰¹å¾
                const copyLength = Math.min(audioFeatures.length, expectedTotalLength);
                expandedFeatures.set(audioFeatures.slice(0, copyLength));
                // å‰©ä½™éƒ¨åˆ†ç”¨é›¶å¡«å……
                if (copyLength < expectedTotalLength) {
                    expandedFeatures.fill(0, copyLength);
                }
                audioFeatures = expandedFeatures;
                console.log(`ç‰¹å¾æ•°ç»„å·²æ‰©å±•ï¼Œæ–°é•¿åº¦: ${audioFeatures.length}`);
            }
            
            // æ£€æŸ¥å½“å‰çª—å£æ‰€éœ€çš„é•¿åº¦
            if (audioFeatures.length < requiredLength) {
                console.warn(`å½“å‰çª—å£æ‰€éœ€é•¿åº¦ä¸è¶³: éœ€è¦ ${requiredLength}, å®é™… ${audioFeatures.length}`);
                // åˆ›å»ºå¡«å……æ•°ç»„
                const paddedFeatures = new Float32Array(requiredLength);
                const copyLength = Math.min(audioFeatures.length, requiredLength);
                paddedFeatures.set(audioFeatures.slice(0, copyLength));
                // å‰©ä½™éƒ¨åˆ†ç”¨é›¶å¡«å……
                if (copyLength < requiredLength) {
                    paddedFeatures.fill(0, copyLength);
                }
                audioFeatures = paddedFeatures;
            }
            
            // ä»ç‰¹å¾ä¸­æå–: au_data æ ¼å¼æ˜¯ [time, channels=30, features=512]
            // Python: input_au = au_data[start_frame:end_frame] å¾—åˆ° [30, 30, 512]
            // ç„¶å input_au = input_au[np.newaxis,:] å˜æˆ [1, 30, 30, 512]
            // ä½†æ¨¡å‹æœŸæœ› [1, 30, 50, 512]ï¼Œæ‰€ä»¥éœ€è¦å–æ›´å¤§çš„çª—å£
            // æ ¹æ®æ¨¡å‹è¾“å…¥ï¼Œtime=50ï¼Œæ‰€ä»¥éœ€è¦å– start_frame-10 åˆ° start_frame+40
            const windowStart = Math.max(0, startFrame - 10);
            const windowSize = expectedTimeFramesAu; // 50
            
            // ä»ç‰¹å¾ä¸­æå–: ç‰¹å¾æ ¼å¼æ˜¯ [time, channels, features] çš„æ‰å¹³æ•°ç»„
            // ç›®æ ‡æ ¼å¼: [channels, time, features] = [30, 50, 512]
            for (let t = 0; t < expectedTimeFramesAu; t++) {
                const frameIdx = windowStart + t;
                if (frameIdx >= frameCount) {
                    // è¶…å‡ºèŒƒå›´ï¼Œç”¨é›¶å¡«å……ï¼ˆinputAuData å·²åˆå§‹åŒ–ä¸º0ï¼‰
                    continue;
                }
                for (let c = 0; c < numChannels; c++) {
                    // æºç´¢å¼•: [time, channels, features] æ ¼å¼
                    // frameIdx * (channels * features) + c * features
                    const srcIdx = (frameIdx * numChannels * featureDim) + (c * featureDim);
                    // ç›®æ ‡ç´¢å¼•: [channels, time, features] æ ¼å¼ï¼ˆæ¨¡å‹æœŸæœ›ï¼‰
                    // c * (time * features) + t * features
                    const dstIdx = (c * expectedTimeFramesAu * featureDim) + (t * featureDim);
                    if (srcIdx + featureDim <= audioFeatures.length && dstIdx + featureDim <= inputAuData.length) {
                        for (let f = 0; f < featureDim; f++) {
                            const val = audioFeatures[srcIdx + f];
                            if (!isNaN(val) && isFinite(val)) {
                                inputAuData[dstIdx + f] = val;
                            }
                        }
                    }
                }
            }
            
            // åˆ›å»º 4 ç»´å¼ é‡: [batch=1, channels=30, time=50, features=512]
            const inputAuTensor = new ort.Tensor('float32', inputAuData, [1, numChannels, expectedTimeFramesAu, featureDim]);
            
            // è°ƒè¯•ï¼šæ£€æŸ¥è¾“å…¥æ•°æ®æ˜¯å¦æœ‰æ•ˆ
            if (startFrame === 0 || startFrame === 60 || startFrame === 120) {
                let validCount = 0;
                let nanCount = 0;
                for (let i = 0; i < Math.min(100, inputAuData.length); i++) {
                    if (isNaN(inputAuData[i])) {
                        nanCount++;
                    } else if (inputAuData[i] !== 0) {
                        validCount++;
                    }
                }
                console.log(`startFrame=${startFrame} è¾“å…¥æ•°æ®æ£€æŸ¥: æœ‰æ•ˆå€¼=${validCount}, NaN=${nanCount}, æ€»é•¿åº¦=${inputAuData.length}`);
            }

            // input_ph çš„æ—¶é—´ç»´åº¦æ˜¯ 30ï¼ˆæ ¹æ® Python ä»£ç ï¼šend_frame = start_frame + 30ï¼‰
            // [batch, time, features] = [1, 30, 2]
            const inputPh = new Float32Array(expectedTimeFramesPh * 2).fill(0);
            const inputPhTensor = new ort.Tensor('float32', inputPh, [1, expectedTimeFramesPh, 2]);

            const w = new ort.Tensor('float32', new Float32Array([1.0]), [1]);
            const sp = new ort.Tensor('int64', new BigInt64Array([2n]), [1]);

            // è¿è¡Œæ¨ç†
            if (!this.audio2mouthModel) {
                throw new Error('éŸ³é¢‘åˆ°å˜´éƒ¨æ¨¡å‹æœªåŠ è½½');
            }
            
            const results = await this.audio2mouthModel.run({
                input_au: inputAuTensor,
                input_ph: inputPhTensor,
                input_sp: sp,
                w: w
            });
            
            if (!results || !results.output) {
                throw new Error('æ¨¡å‹æ¨ç†è¿”å›ç©ºç»“æœ');
            }

            const output = results.output.data;
            
            if (!output || output.length === 0) {
                throw new Error('æ¨¡å‹è¾“å‡ºä¸ºç©º');
            }
            
            // å¤„ç†è¾“å‡ºï¼ˆç±»ä¼¼ Python ç‰ˆæœ¬çš„é€»è¾‘ï¼‰
            // æ ¹æ® Python ä»£ç ï¼Œè¾“å‡ºåº”è¯¥æ˜¯ [batch, time=30, features=32]
            const outputShape = results.output.dims || [1, expectedTimeFramesPh, 32];
            const numParams = outputShape[2] || 32;
            const totalFrames = outputShape[1] || expectedTimeFramesPh;
            
            // è°ƒè¯•ï¼šæ£€æŸ¥æ¨¡å‹è¾“å‡ºæ˜¯å¦å˜åŒ–
            const firstFrameParams = [];
            for (let ii = 0; ii < numParams; ii++) {
                firstFrameParams.push(output[ii]);
            }
            console.log(`startFrame=${startFrame}, startTime=${startTime.toFixed(3)}, æ¨¡å‹è¾“å‡ºå‰5ä¸ªå‚æ•°: [${firstFrameParams.slice(0, 5).map(v => v.toFixed(3)).join(', ')}]`);
            
            // æ£€æŸ¥è¾“å…¥ç‰¹å¾æ˜¯å¦ä¸åŒ
            if (startFrame === 0 || startFrame === 60 || startFrame === 120) {
                const sampleFeatureValues = [];
                for (let i = 0; i < 10; i++) {
                    sampleFeatureValues.push(inputAuData[i].toFixed(3));
                }
                console.log(`startFrame=${startFrame} è¾“å…¥ç‰¹å¾å‰10ä¸ªå€¼: [${sampleFeatureValues.join(', ')}]`);
            }
            
            // è¾…åŠ©å‡½æ•°
            const round = (value, decimals) => {
                if (typeof value !== 'number' || isNaN(value)) return 0;
                return Math.round(value * Math.pow(10, decimals)) / Math.pow(10, decimals);
            };
            
            // å¤„ç†è¾“å‡ºå¸§
            // Python ä»£ç é€»è¾‘ï¼š
            // - å¦‚æœ start_time == 0.0 ä¸” !is_end: å¤„ç†å‰ (30 * interval - frag) å¸§
            // - å¦‚æœ start_time > 0.0 ä¸” !is_end: å¤„ç† frag åˆ° (30 * interval - frag) å¸§
            // - å¦‚æœ is_end: å¤„ç† frag åˆ° (30 * interval) å¸§
            const frag = Math.floor(interval * 30 / 5 + 0.5); // frag = 6
            
            for (let tt = 0; tt < totalFrames; tt++) {
                const frameId = startFrame + tt;
                const paramFrame = {};
                
                for (let ii = 0; ii < numParams; ii++) {
                    const index = tt * numParams + ii;
                    const value = index < output.length ? output[index] : 0;
                    paramFrame[String(ii)] = round(value, 3);
                }
                
                // å¤„ç†é‡å åŒºåŸŸï¼ˆç±»ä¼¼ Python ç‰ˆæœ¬çš„é€»è¾‘ï¼‰
                if (startTime === 0.0 && !isEnd) {
                    // ç¬¬ä¸€æ®µï¼Œè·³è¿‡æœ€åçš„ frag å¸§
                    if (tt < totalFrames - frag) {
                        paramRes.push(paramFrame);
                    }
                } else if (startTime > 0.0 && !isEnd) {
                    // ä¸­é—´æ®µï¼Œå¤„ç† frag åˆ° (totalFrames - frag) å¸§
                    if (tt >= frag && tt < totalFrames - frag) {
                        if (frameId < paramRes.length) {
                            // é‡å åŒºåŸŸï¼Œè¿›è¡Œæ··åˆ
                            const scale = Math.min((paramRes.length - frameId) / frag, 1.0);
                            for (let key in paramFrame) {
                                const oldValue = paramRes[frameId]?.[key] || 0;
                                paramFrame[key] = (1 - scale) * paramFrame[key] + scale * oldValue;
                            }
                            paramRes[frameId] = paramFrame;
                        } else {
                            paramRes.push(paramFrame);
                        }
                    }
                } else {
                    // æœ€åä¸€æ®µï¼Œå¤„ç† frag åˆ° totalFrames å¸§
                    if (tt >= frag) {
                        if (frameId < paramRes.length) {
                            // é‡å åŒºåŸŸï¼Œè¿›è¡Œæ··åˆ
                            const scale = Math.min((paramRes.length - frameId) / frag, 1.0);
                            for (let key in paramFrame) {
                                const oldValue = paramRes[frameId]?.[key] || 0;
                                paramFrame[key] = (1 - scale) * paramFrame[key] + scale * oldValue;
                            }
                            paramRes[frameId] = paramFrame;
                        } else {
                            paramRes.push(paramFrame);
                        }
                    }
                }
            }

            if (isEnd) break;

            startTime = endTime - (frag / 10);
            endTime = startTime + interval;
        }

        // å¹³æ»‘å¤„ç†
        return this.smoothParams(paramRes);
    }

    smoothParams(params) {
        // å®ç°ä½é€šæ»¤æ³¢å¹³æ»‘
        // ç®€åŒ–ç‰ˆå®ç°
        return params;
    }

    async generateVideo() {
        // æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶ï¼šä¼˜å…ˆä½¿ç”¨æ–‡ä»¶è¾“å…¥ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ this.audioFileï¼ˆé»˜è®¤éŸ³é¢‘æˆ–å½•éŸ³ï¼‰
        const audioFileInput = document.getElementById('audioFile');
        const audioFile = audioFileInput?.files[0] || this.audioFile;
        
        if (!audioFile) {
            this.updateStatus('error', 'è¯·å…ˆä¸Šä¼ éŸ³é¢‘æ–‡ä»¶æˆ–ä½¿ç”¨é»˜è®¤ç¤ºä¾‹éŸ³é¢‘');
            return;
        }

        if (!this.avatarData) {
            this.updateStatus('error', 'è¯·å…ˆåŠ è½½ Avatar æ•°æ®');
            return;
        }

        try {
            console.log('å¼€å§‹ç”Ÿæˆè§†é¢‘...');
            console.log('éŸ³é¢‘æ–‡ä»¶:', audioFile.name);
            console.log('Avatar æ•°æ®:', this.avatarData ? Object.keys(this.avatarData).length + ' ä¸ªæ–‡ä»¶' : 'æ— ');
            
            // åˆå§‹åŒ–æ¨¡å‹
            this.updateStatus('', 'æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹...');
            await this.initializeModels();
            console.log('âœ“ æ¨¡å‹åˆå§‹åŒ–å®Œæˆ');

            // åŠ è½½ Avatar æ•°æ®ï¼ˆå¦‚æœè¿˜æ²¡æœ‰åŠ è½½ï¼‰
            if (this.avatarData && Object.keys(this.avatarData).length > 0) {
                this.updateStatus('', 'æ­£åœ¨åŠ è½½ Avatar æ•°æ®...');
                await this.loadAvatarData(this.avatarData);
                console.log('âœ“ Avatar æ•°æ®åŠ è½½å®Œæˆ');
            } else {
                throw new Error('è¯·å…ˆåŠ è½½ Avatar æ•°æ®');
            }

            // ç¡®å®šç›®æ ‡å¸§æ•°ï¼ˆåŸºäºè§†é¢‘å¸§æ•°ï¼Œç¡®ä¿éŸ³é¢‘å’Œè§†é¢‘å¯¹é½ï¼‰
            const videoFrameCount = this.bgVideoFrames ? this.bgVideoFrames.length : 150;
            const fps = 30;
            const targetFrameCount = videoFrameCount;
            
            console.log('è§†é¢‘å¸§æ•°:', videoFrameCount, 'ç›®æ ‡éŸ³é¢‘å¸§æ•°:', targetFrameCount);
            
            // å¤„ç†éŸ³é¢‘ï¼ˆä¼ å…¥ç›®æ ‡å¸§æ•°ï¼Œç¡®ä¿éŸ³é¢‘ç‰¹å¾å’Œè§†é¢‘å¸§æ•°åŒ¹é…ï¼‰
            this.updateStatus('', 'æ­£åœ¨å¤„ç†éŸ³é¢‘...');
            const mouthParams = await this.processAudio(audioFile, targetFrameCount);
            console.log('âœ“ éŸ³é¢‘å¤„ç†å®Œæˆï¼Œç”Ÿæˆ', mouthParams.length, 'å¸§å‚æ•°');
            
            if (!mouthParams || mouthParams.length === 0) {
                throw new Error('æœªèƒ½ç”Ÿæˆå˜´éƒ¨å‚æ•°');
            }
            
            // ç¡®ä¿å˜´éƒ¨å‚æ•°å¸§æ•°å’Œè§†é¢‘å¸§æ•°åŒ¹é…
            if (mouthParams.length !== targetFrameCount) {
                console.warn(`è­¦å‘Šï¼šå˜´éƒ¨å‚æ•°å¸§æ•° (${mouthParams.length}) ä¸è§†é¢‘å¸§æ•° (${targetFrameCount}) ä¸åŒ¹é…ï¼Œå°†è¿›è¡Œè°ƒæ•´`);
                // å¦‚æœå‚æ•°å¸§æ•°å°‘äºè§†é¢‘å¸§æ•°ï¼Œé‡å¤æœ€åä¸€å¸§
                // å¦‚æœå‚æ•°å¸§æ•°å¤šäºè§†é¢‘å¸§æ•°ï¼Œæˆªæ–­
                while (mouthParams.length < targetFrameCount) {
                    mouthParams.push(mouthParams[mouthParams.length - 1]);
                }
                if (mouthParams.length > targetFrameCount) {
                    mouthParams.splice(targetFrameCount);
                }
                console.log('è°ƒæ•´åå˜´éƒ¨å‚æ•°å¸§æ•°:', mouthParams.length);
            }

            // ç”Ÿæˆè§†é¢‘å¸§
            this.updateStatus('', 'æ­£åœ¨ç”Ÿæˆè§†é¢‘å¸§...');
            const frames = await this.generateFrames(mouthParams);

            // åˆæˆè§†é¢‘
            this.updateStatus('', 'æ­£åœ¨åˆæˆè§†é¢‘...');
            const videoBlob = await this.composeVideo(frames, audioFile);

            // æ˜¾ç¤ºç»“æœ
            const videoElement = document.getElementById('outputVideo');
            videoElement.src = URL.createObjectURL(videoBlob);
            videoElement.classList.remove('hidden');

            const downloadLink = document.getElementById('downloadLink');
            downloadLink.href = URL.createObjectURL(videoBlob);
            downloadLink.classList.remove('hidden');

            this.updateStatus('success', 'è§†é¢‘ç”Ÿæˆå®Œæˆï¼');
        } catch (error) {
            const errorMessage = error?.message || error?.toString() || 'æœªçŸ¥é”™è¯¯';
            const errorStack = error?.stack || '';
            console.error('ç”Ÿæˆè§†é¢‘å¤±è´¥:', error);
            console.error('é”™è¯¯å †æ ˆ:', errorStack);
            this.updateStatus('error', `ç”Ÿæˆå¤±è´¥: ${errorMessage}`);
            
            // æ˜¾ç¤ºæ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            if (errorMessage.includes('model') || errorMessage.includes('æ¨¡å‹')) {
                this.updateStatus('error', `æ¨¡å‹é”™è¯¯: ${errorMessage}ã€‚è¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨ã€‚`);
            } else if (errorMessage.includes('audio') || errorMessage.includes('éŸ³é¢‘')) {
                this.updateStatus('error', `éŸ³é¢‘å¤„ç†é”™è¯¯: ${errorMessage}ã€‚è¯·æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ ¼å¼ã€‚`);
            } else {
                this.updateStatus('error', `ç”Ÿæˆå¤±è´¥: ${errorMessage}ã€‚è¯·æŸ¥çœ‹æ§åˆ¶å°è·å–è¯¦ç»†ä¿¡æ¯ã€‚`);
            }
        }
    }

    async generateFrames(mouthParams) {
        const frames = [];
        const totalFrames = mouthParams.length;

        for (let i = 0; i < totalFrames; i++) {
            // æ›´æ–°è¿›åº¦
            const progress = ((i + 1) / totalFrames * 100).toFixed(1);
            this.updateProgress(progress);

            // ç”Ÿæˆå•å¸§
            const frame = await this.generateFrame(mouthParams[i], i);
            frames.push(frame);
        }

        return frames;
    }

    async generateFrame(mouthParams, frameIndex) {
        // é€‰æ‹©èƒŒæ™¯å¸§
        let bgFrame = null;
        
        if (this.bgVideoFrames && this.bgVideoFrames.length > 0) {
            // ä½¿ç”¨èƒŒæ™¯è§†é¢‘å¸§
            const bgFrameIndex = frameIndex % this.bgVideoFrames.length;
            bgFrame = this.bgVideoFrames[bgFrameIndex];
        } else if (this.refFrames && this.refFrames.length > 0) {
            // å¦‚æœæ²¡æœ‰èƒŒæ™¯è§†é¢‘å¸§ï¼Œä½¿ç”¨å‚è€ƒå¸§ä½œä¸ºèƒŒæ™¯
            const refFrameIndex = frameIndex % this.refFrames.length;
            const refFrameData = this.refFrames[refFrameIndex];
            
            // ä»å‚è€ƒå¸§åˆ›å»º ImageData
            if (refFrameData.url) {
                const img = new Image();
                await new Promise((resolve, reject) => {
                    img.onload = () => {
                        const canvas = document.createElement('canvas');
                        canvas.width = img.width;
                        canvas.height = img.height;
                        const ctx = canvas.getContext('2d');
                        ctx.drawImage(img, 0, 0);
                        bgFrame = ctx.getImageData(0, 0, canvas.width, canvas.height);
                        resolve();
                    };
                    img.onerror = reject;
                    img.src = refFrameData.url;
                });
            }
        } else {
            // å¦‚æœéƒ½æ²¡æœ‰ï¼Œåˆ›å»ºä¸€ä¸ªç©ºç™½å¸§
            const canvas = document.createElement('canvas');
            canvas.width = 512;
            canvas.height = 512;
            const ctx = canvas.getContext('2d');
            ctx.fillStyle = '#f0f0f0';
            ctx.fillRect(0, 0, canvas.width, canvas.height);
            bgFrame = ctx.getImageData(0, 0, canvas.width, canvas.height);
        }

        // é€‰æ‹©å‚è€ƒå¸§ç”¨äºç”Ÿæˆå˜´éƒ¨
        // Python ä»£ç : self.generator(self.ref_img_list[bg_frame_id], ...)
        // bg_frame_id åº”è¯¥ä¸èƒŒæ™¯å¸§ç´¢å¼•ä¸€è‡´
        const bgFrameIndex = frameIndex % (this.bgVideoFrames?.length || this.refFrames?.length || 1);
        let refFrame = null;
        
        if (this.refFrames && this.refFrames.length > 0) {
            // ä½¿ç”¨ä¸èƒŒæ™¯å¸§ç›¸åŒçš„ç´¢å¼•æ¥é€‰æ‹©å‚è€ƒå¸§
            const refFrameIndex = bgFrameIndex % this.refFrames.length;
            const refFrameData = this.refFrames[refFrameIndex];
            if (refFrameData && refFrameData.url) {
                const img = new Image();
                await new Promise((resolve, reject) => {
                    img.onload = () => {
                        const canvas = document.createElement('canvas');
                        canvas.width = img.width;
                        canvas.height = img.height;
                        const ctx = canvas.getContext('2d');
                        ctx.drawImage(img, 0, 0);
                        refFrame = ctx.getImageData(0, 0, canvas.width, canvas.height);
                        resolve();
                    };
                    img.onerror = reject;
                    img.src = refFrameData.url;
                });
            }
        }
        
        // ä½¿ç”¨ç”Ÿæˆå™¨æ¨¡å‹ç”Ÿæˆå˜´éƒ¨å›¾åƒï¼ˆå¦‚æœæœ‰æ¨¡å‹ï¼‰
        let mouthImage = null;
        if (this.generatorModel && refFrame) {
            mouthImage = await this.generateMouthImage(mouthParams, refFrame, frameIndex);
        } else if (refFrame) {
            // ç®€åŒ–ç‰ˆï¼šä½¿ç”¨å‚è€ƒå¸§å¹¶æ ¹æ®å‚æ•°è¿›è¡Œç®€å•å˜å½¢
            mouthImage = await this.generateMouthImageSimple(mouthParams, refFrame);
        }

        // åˆå¹¶åˆ°èƒŒæ™¯
        if (mouthImage && this.faceBox) {
            const finalFrame = this.mergeMouthToBackground(mouthImage, bgFrame);
            return finalFrame;
        }

        // å¦‚æœæ²¡æœ‰å˜´éƒ¨å›¾åƒï¼Œç›´æ¥è¿”å›èƒŒæ™¯å¸§
        return bgFrame;
    }

    async generateMouthImage(mouthParams, refFrame, frameIndex = 0) {
        // ä½¿ç”¨ç”Ÿæˆå™¨æ¨¡å‹ç”Ÿæˆå˜´éƒ¨å›¾åƒ
        // éœ€è¦å…ˆè¿è¡Œç¼–ç å™¨è·å–ç‰¹å¾ï¼Œç„¶åç”¨ç‰¹å¾+å‚æ•°è°ƒç”¨ç”Ÿæˆå™¨
        if (!this.generatorModel || !this.encoderModel) {
            console.warn('ç”Ÿæˆå™¨æˆ–ç¼–ç å™¨æ¨¡å‹æœªåŠ è½½ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬');
            return null;
        }
        
        try {
            // 1. å…ˆè¿è¡Œç¼–ç å™¨è·å–ç‰¹å¾åˆ—è¡¨
            const refImageData = refFrame;
            const width = refImageData.width;
            const height = refImageData.height;
            
            // è°ƒæ•´å›¾åƒå¤§å°åˆ° 384x384ï¼ˆç¼–ç å™¨æœŸæœ›çš„è¾“å…¥ï¼‰
            const targetSize = 384;
            const canvas = document.createElement('canvas');
            canvas.width = targetSize;
            canvas.height = targetSize;
            const ctx = canvas.getContext('2d');
            
            // åˆ›å»ºä¸´æ—¶canvasç»˜åˆ¶å‚è€ƒå¸§
            const tempCanvas = document.createElement('canvas');
            tempCanvas.width = width;
            tempCanvas.height = height;
            const tempCtx = tempCanvas.getContext('2d');
            tempCtx.putImageData(refImageData, 0, 0);
            
            // è°ƒæ•´å¤§å°
            ctx.drawImage(tempCanvas, 0, 0, targetSize, targetSize);
            const resizedImageData = ctx.getImageData(0, 0, targetSize, targetSize);
            
            // è½¬æ¢ä¸º [1, 3, 384, 384] æ ¼å¼çš„ tensorï¼Œå½’ä¸€åŒ–åˆ° [-1, 1]
            const refImageArray = new Float32Array(1 * 3 * targetSize * targetSize);
            const data = resizedImageData.data;
            
            for (let y = 0; y < targetSize; y++) {
                for (let x = 0; x < targetSize; x++) {
                    const idx = (y * targetSize + x) * 4;
                    const r = data[idx];
                    const g = data[idx + 1];
                    const b = data[idx + 2];
                    
                    // å½’ä¸€åŒ–åˆ° [-1, 1]ï¼ˆä½¿ç”¨ transforms.Normalize([0.5], [0.5]) çš„æ•ˆæœï¼‰
                    const rIdx = (0 * targetSize * targetSize) + (y * targetSize) + x;
                    const gIdx = (1 * targetSize * targetSize) + (y * targetSize) + x;
                    const bIdx = (2 * targetSize * targetSize) + (y * targetSize) + x;
                    
                    refImageArray[rIdx] = (r / 255.0) * 2.0 - 1.0;
                    refImageArray[gIdx] = (g / 255.0) * 2.0 - 1.0;
                    refImageArray[bIdx] = (b / 255.0) * 2.0 - 1.0;
                }
            }
            
            const refImageTensor = new ort.Tensor('float32', refImageArray, [1, 3, targetSize, targetSize]);
            
            // è¿è¡Œç¼–ç å™¨è·å–ç‰¹å¾åˆ—è¡¨
            const encoderResults = await this.encoderModel.run({
                ref_image: refImageTensor
            });
            
            // ç¼–ç å™¨ç°åœ¨è¿”å›4ä¸ªç‹¬ç«‹è¾“å‡º: output_0, output_1, output_2, output_3
            // æ ¹æ®ç¼–ç å™¨è¾“å‡ºå½¢çŠ¶: [(1, 3, 384, 384), (1, 16, 192, 192), (1, 32, 96, 96), (1, 64, 48, 48)]
            const encoderOutputs = [];
            if (encoderResults.output_0 && encoderResults.output_1 && encoderResults.output_2 && encoderResults.output_3) {
                // å¤šä¸ªç‹¬ç«‹è¾“å‡º
                encoderOutputs.push(encoderResults.output_0); // (1, 3, 384, 384)
                encoderOutputs.push(encoderResults.output_1); // (1, 16, 192, 192)
                encoderOutputs.push(encoderResults.output_2); // (1, 32, 96, 96)
                encoderOutputs.push(encoderResults.output_3); // (1, 64, 48, 48)
            } else {
                // å…¼å®¹æ—§æ ¼å¼ï¼ˆå¦‚æœåªæœ‰ä¸€ä¸ªè¾“å‡ºï¼‰
                console.warn('ç¼–ç å™¨è¾“å‡ºæ ¼å¼å¼‚å¸¸ï¼Œå°è¯•å…¼å®¹æ¨¡å¼');
                if (encoderResults.output) {
                    encoderOutputs.push(encoderResults.output);
                } else {
                    // å°è¯•æŒ‰ç´¢å¼•è·å–
                    for (let i = 0; i < 4; i++) {
                        const key = `output_${i}`;
                        if (encoderResults[key]) {
                            encoderOutputs.push(encoderResults[key]);
                        }
                    }
                }
            }
            
            if (encoderOutputs.length < 4) {
                throw new Error(`ç¼–ç å™¨è¾“å‡ºæ•°é‡ä¸è¶³: æœŸæœ›4ä¸ªï¼Œå®é™…${encoderOutputs.length}ã€‚å¯ç”¨é”®: ${Object.keys(encoderResults).join(', ')}`);
            }
            
            // 2. å‡†å¤‡å‚æ•°å€¼ï¼ˆ32ä¸ªå‚æ•°ï¼‰
            // Python ä»£ç : 
            //   param_val = []
            //   for key in param_res:
            //       param_val.append(param_res[key])
            // ç”±äº Python 3.7+ å­—å…¸ä¿æŒæ’å…¥é¡ºåºï¼Œä¸”å‚æ•°æ˜¯æŒ‰ p_list é¡ºåºæ·»åŠ çš„
            // æ‰€ä»¥åº”è¯¥æŒ‰ç…§ p_list çš„é¡ºåºæå–ï¼š["0", "1", ..., "31"]
            const paramValues = [];
            const pList = [];
            for (let i = 0; i < 32; i++) {
                pList.push(String(i));
            }
            // æŒ‰ç…§ p_list é¡ºåºæå–å‚æ•°å€¼ï¼ˆä¸ Python ä»£ç ä¸€è‡´ï¼‰
            for (const key of pList) {
                const value = mouthParams[key] || 0;
                paramValues.push(value);
            }
            
            // è°ƒè¯•ï¼šæ£€æŸ¥å‚æ•°å€¼èŒƒå›´
            if (frameIndex === 0 || frameIndex % 60 === 0) {
                const minVal = Math.min(...paramValues);
                const maxVal = Math.max(...paramValues);
                const avgVal = paramValues.reduce((a, b) => a + b, 0) / paramValues.length;
                console.log(`å¸§ ${frameIndex} å‚æ•°å€¼èŒƒå›´: [${minVal.toFixed(3)}, ${maxVal.toFixed(3)}], å¹³å‡å€¼: ${avgVal.toFixed(3)}`);
                console.log(`  å‰5ä¸ªå‚æ•°: [${paramValues.slice(0, 5).map(v => v.toFixed(3)).join(', ')}]`);
            }
            
            const paramTensor = new ort.Tensor('float32', new Float32Array(paramValues), [1, 32]);
            
            // 3. è¿è¡Œç”Ÿæˆå™¨æ¨¡å‹
            // ç”Ÿæˆå™¨éœ€è¦: [input, skip1, skip0, skip] å’Œ paramsï¼ˆä¸ç¼–ç å™¨è¾“å‡ºé¡ºåºä¸€è‡´ï¼‰
            // input = encoderOutputs[0] (1, 3, 384, 384)
            // skip1 = encoderOutputs[1] (1, 16, 192, 192)
            // skip0 = encoderOutputs[2] (1, 32, 96, 96)
            // skip = encoderOutputs[3] (1, 64, 48, 48)
            const results = await this.generatorModel.run({
                input: encoderOutputs[0],
                skip1: encoderOutputs[1],
                skip0: encoderOutputs[2],
                skip: encoderOutputs[3],
                params: paramTensor
            });
            
            // å¤„ç†è¾“å‡º
            const output = results.output;
            if (!output) {
                throw new Error('æ¨¡å‹è¾“å‡ºä¸ºç©º');
            }
            
            // å°†è¾“å‡ºè½¬æ¢ä¸º ImageData
            const outputData = output.data;
            const outputDims = output.dims || [1, 3, targetSize, targetSize];
            const outputHeight = outputDims[2] || targetSize;
            const outputWidth = outputDims[3] || targetSize;
            
            const outputImageData = new ImageData(outputWidth, outputHeight);
            const outputArray = outputImageData.data;
            
            // ä» [1, 3, H, W] è½¬æ¢ä¸º RGBA ImageData
            // Python ä»£ç : mouth_image = (mouth_image / 2 + 0.5).clamp(0, 1) * 255
            // ç­‰ä»·äº: (mouth_image + 1) * 127.5
            for (let y = 0; y < outputHeight; y++) {
                for (let x = 0; x < outputWidth; x++) {
                    const rIdx = (0 * outputHeight * outputWidth) + (y * outputWidth) + x;
                    const gIdx = (1 * outputHeight * outputWidth) + (y * outputWidth) + x;
                    const bIdx = (2 * outputHeight * outputWidth) + (y * outputWidth) + x;
                    
                    const idx = (y * outputWidth + x) * 4;
                    // ä» [-1, 1] åå½’ä¸€åŒ–åˆ° [0, 255]
                    // Python: (x / 2 + 0.5) * 255 = (x + 1) * 127.5
                    outputArray[idx] = Math.max(0, Math.min(255, (outputData[rIdx] + 1) * 127.5));
                    outputArray[idx + 1] = Math.max(0, Math.min(255, (outputData[gIdx] + 1) * 127.5));
                    outputArray[idx + 2] = Math.max(0, Math.min(255, (outputData[bIdx] + 1) * 127.5));
                    outputArray[idx + 3] = 255;
                }
            }
            
            return outputImageData;
        } catch (error) {
            console.error('ç”Ÿæˆå˜´éƒ¨å›¾åƒå¤±è´¥:', error);
            return null;
        }
    }
    
    async generateMouthImageSimple(mouthParams, refFrame) {
        // ç®€åŒ–ç‰ˆï¼šæ ¹æ®å˜´éƒ¨å‚æ•°å¯¹å‚è€ƒå¸§è¿›è¡Œç®€å•å˜å½¢
        // åˆ›å»ºä¸€ä¸ª canvas æ¥ç»˜åˆ¶å˜å½¢çš„å˜´éƒ¨
        const canvas = document.createElement('canvas');
        canvas.width = refFrame.width;
        canvas.height = refFrame.height;
        const ctx = canvas.getContext('2d');
        
        // ç»˜åˆ¶å‚è€ƒå¸§
        ctx.putImageData(refFrame, 0, 0);
        
        // å¦‚æœæœ‰ faceBoxï¼Œåœ¨å˜´éƒ¨åŒºåŸŸåº”ç”¨å˜å½¢
        if (this.faceBox) {
            const { y1, y2, x1, x2 } = this.faceBox;
            const mouthWidth = x2 - x1;
            const mouthHeight = y2 - y1;
            const centerX = (x1 + x2) / 2;
            const centerY = (y1 + y2) / 2;
            
            // è·å–å˜´éƒ¨åŒºåŸŸçš„å›¾åƒæ•°æ®
            const imageData = ctx.getImageData(x1, y1, mouthWidth, mouthHeight);
            const data = imageData.data;
            
            // è®¡ç®—å˜´éƒ¨å‚æ•°çš„å˜åŒ–ï¼ˆä½¿ç”¨å‰å‡ ä¸ªä¸»è¦å‚æ•°ï¼‰
            const paramKeys = ['0', '1', '2', '3', '4', '5'];
            let paramSum = 0;
            for (const key of paramKeys) {
                paramSum += mouthParams[key] || 0;
            }
            const avgParam = paramSum / paramKeys.length;
            
            // æ ¹æ®å‚æ•°å€¼è°ƒæ•´å˜´éƒ¨åŒºåŸŸçš„é¢œè‰²å’Œå½¢çŠ¶
            // ä½¿ç”¨ç®€å•çš„å¾„å‘å˜å½¢å’Œé¢œè‰²è°ƒæ•´
            for (let y = 0; y < mouthHeight; y++) {
                for (let x = 0; x < mouthWidth; x++) {
                    const dx = x - mouthWidth / 2;
                    const dy = y - mouthHeight / 2;
                    const dist = Math.sqrt(dx * dx + dy * dy);
                    const maxDist = Math.min(mouthWidth, mouthHeight) / 2;
                    
                    // æ ¹æ®è·ç¦»å’Œå‚æ•°è®¡ç®—å˜å½¢å¼ºåº¦
                    const normalizedDist = dist / maxDist;
                    const intensity = (avgParam - 0.5) * 0.5; // è°ƒæ•´å¼ºåº¦
                    const factor = 1 - normalizedDist * intensity;
                    
                    const idx = (y * mouthWidth + x) * 4;
                    // è°ƒæ•´é¢œè‰²ä»¥æ¨¡æ‹Ÿå˜´éƒ¨è¿åŠ¨
                    data[idx] = Math.max(0, Math.min(255, data[idx] * (1 + factor * 0.3)));     // R
                    data[idx + 1] = Math.max(0, Math.min(255, data[idx + 1] * (1 + factor * 0.15))); // G
                    data[idx + 2] = Math.max(0, Math.min(255, data[idx + 2] * (1 + factor * 0.2))); // B
                }
            }
            
            // å°†ä¿®æ”¹åçš„å›¾åƒæ•°æ®æ”¾å›
            ctx.putImageData(imageData, x1, y1);
        } else {
            // å¦‚æœæ²¡æœ‰ faceBoxï¼Œåœ¨æ•´ä¸ªå›¾åƒä¸­å¿ƒåº”ç”¨ç®€å•å˜å½¢
            const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            const data = imageData.data;
            
            const paramValues = Object.values(mouthParams);
            const avgParam = paramValues.reduce((a, b) => a + b, 0) / paramValues.length;
            const intensity = (avgParam - 0.5) * 0.3;
            
            const centerX = canvas.width / 2;
            const centerY = canvas.height * 0.6;
            const radius = Math.min(canvas.width, canvas.height) * 0.15;
            
            for (let y = 0; y < canvas.height; y++) {
                for (let x = 0; x < canvas.width; x++) {
                    const dx = x - centerX;
                    const dy = y - centerY;
                    const dist = Math.sqrt(dx * dx + dy * dy);
                    
                    if (dist < radius) {
                        const idx = (y * canvas.width + x) * 4;
                        const factor = 1 - (dist / radius) * intensity;
                        data[idx] = Math.min(255, data[idx] * (1 + factor * 0.2));
                        data[idx + 1] = Math.min(255, data[idx + 1] * (1 + factor * 0.1));
                        data[idx + 2] = Math.min(255, data[idx + 2] * (1 + factor * 0.15));
                    }
                }
            }
            
            ctx.putImageData(imageData, 0, 0);
        }
        
        return ctx.getImageData(0, 0, canvas.width, canvas.height);
    }
    
    mergeMouthToBackground(mouthImage, bgFrame) {
        if (!this.faceBox || !mouthImage) {
            return bgFrame;
        }
        
        // åˆ›å»ºè¾“å‡º canvas
        const canvas = document.createElement('canvas');
        canvas.width = bgFrame.width;
        canvas.height = bgFrame.height;
        const ctx = canvas.getContext('2d');
        
        // ç»˜åˆ¶èƒŒæ™¯å¸§
        ctx.putImageData(bgFrame, 0, 0);
        
        // è·å–å˜´éƒ¨åŒºåŸŸ
        const { y1, y2, x1, x2 } = this.faceBox;
        const mouthWidth = x2 - x1;
        const mouthHeight = y2 - y1;
        
        // åˆ›å»ºä¸´æ—¶ canvas æ¥è°ƒæ•´å˜´éƒ¨å›¾åƒå¤§å°
        const mouthCanvas = document.createElement('canvas');
        mouthCanvas.width = mouthWidth;
        mouthCanvas.height = mouthHeight;
        const mouthCtx = mouthCanvas.getContext('2d');
        
        // è°ƒæ•´å˜´éƒ¨å›¾åƒå¤§å°
        mouthCtx.drawImage(
            this.imageDataToCanvas(mouthImage).canvas,
            0, 0, mouthImage.width, mouthImage.height,
            0, 0, mouthWidth, mouthHeight
        );
        
        const mouthImageData = mouthCtx.getImageData(0, 0, mouthWidth, mouthHeight);
        const bgImageData = ctx.getImageData(x1, y1, mouthWidth, mouthHeight);
        
        // ä½¿ç”¨ mergeMask è¿›è¡Œæ··åˆ
        if (this.mergeMask && this.mergeMask.length === mouthWidth * mouthHeight) {
            for (let i = 0; i < mouthWidth * mouthHeight; i++) {
                const maskValue = this.mergeMask[i];
                const bgIdx = i * 4;
                const mouthIdx = i * 4;
                
                bgImageData.data[bgIdx] = mouthImageData.data[mouthIdx] * (1 - maskValue) + bgImageData.data[bgIdx] * maskValue;
                bgImageData.data[bgIdx + 1] = mouthImageData.data[mouthIdx + 1] * (1 - maskValue) + bgImageData.data[bgIdx + 1] * maskValue;
                bgImageData.data[bgIdx + 2] = mouthImageData.data[mouthIdx + 2] * (1 - maskValue) + bgImageData.data[bgIdx + 2] * maskValue;
                bgImageData.data[bgIdx + 3] = 255; // Alpha
            }
        } else {
            // å¦‚æœæ²¡æœ‰ mergeMaskï¼Œç›´æ¥æ›¿æ¢
            for (let i = 0; i < mouthWidth * mouthHeight; i++) {
                const idx = i * 4;
                bgImageData.data[idx] = mouthImageData.data[idx];
                bgImageData.data[idx + 1] = mouthImageData.data[idx + 1];
                bgImageData.data[idx + 2] = mouthImageData.data[idx + 2];
                bgImageData.data[idx + 3] = 255;
            }
        }
        
        // å°†æ··åˆåçš„å›¾åƒæ”¾å›èƒŒæ™¯
        ctx.putImageData(bgImageData, x1, y1);
        
        return ctx.getImageData(0, 0, canvas.width, canvas.height);
    }
    
    imageDataToCanvas(imageData) {
        const canvas = document.createElement('canvas');
        canvas.width = imageData.width;
        canvas.height = imageData.height;
        const ctx = canvas.getContext('2d');
        ctx.putImageData(imageData, 0, 0);
        return { canvas, ctx };
    }

    async composeVideo(frames, audioFile) {
        if (!frames || frames.length === 0) {
            throw new Error('æ²¡æœ‰å¯ç”¨çš„è§†é¢‘å¸§');
        }

        console.log('å¼€å§‹åˆæˆè§†é¢‘ï¼Œå…±', frames.length, 'å¸§');
        
        // è·å–ç¬¬ä¸€å¸§çš„å°ºå¯¸
        const firstFrame = frames[0];
        const width = firstFrame.width;
        const height = firstFrame.height;
        const fps = 30;

        // åˆ›å»º canvas ç”¨äºç»˜åˆ¶å¸§
        const canvas = document.createElement('canvas');
        canvas.width = width;
        canvas.height = height;
        const ctx = canvas.getContext('2d');

        // åˆ›å»ºè§†é¢‘æµ
        const videoStream = canvas.captureStream(fps);
        
        // åˆ›å»ºéŸ³é¢‘æµï¼ˆä½¿ç”¨å·²å¤„ç†çš„éŸ³é¢‘ï¼‰
        let audioStream = null;
        if (this.processedAudioBuffer) {
            try {
                const targetSampleRate = 16000;
                
                // åˆ›å»º AudioContext ç”¨äºéŸ³é¢‘è¾“å‡ºï¼ˆ16kHzï¼‰
                if (!this.outputAudioContext) {
                    this.outputAudioContext = new (window.AudioContext || window.webkitAudioContext)({
                        sampleRate: targetSampleRate
                    });
                }
                
                // ç›´æ¥ä½¿ç”¨å·²å¤„ç†çš„éŸ³é¢‘ç¼“å†²åŒº
                const processedBuffer = this.processedAudioBuffer;
                
                // åˆ›å»ºéŸ³é¢‘æºèŠ‚ç‚¹
                const source = this.outputAudioContext.createBufferSource();
                source.buffer = processedBuffer;
                
                // åˆ›å»º MediaStreamDestination æ¥è·å–éŸ³é¢‘æµ
                const destination = this.outputAudioContext.createMediaStreamDestination();
                source.connect(destination);
                
                // å¼€å§‹æ’­æ”¾éŸ³é¢‘
                source.start(0);
                
                audioStream = destination.stream;
                console.log('ä½¿ç”¨å·²å¤„ç†çš„éŸ³é¢‘:', {
                    é‡‡æ ·ç‡: processedBuffer.sampleRate,
                    é€šé“æ•°: processedBuffer.numberOfChannels,
                    æ—¶é•¿: processedBuffer.duration.toFixed(2) + 'ç§’',
                    é‡‡æ ·æ•°: processedBuffer.length
                });
            } catch (error) {
                console.warn('æ— æ³•æ·»åŠ éŸ³é¢‘åˆ°è§†é¢‘:', error);
                // ç»§ç»­ç”Ÿæˆæ²¡æœ‰éŸ³é¢‘çš„è§†é¢‘
            }
        } else if (audioFile) {
            console.warn('æœªæ‰¾åˆ°å·²å¤„ç†çš„éŸ³é¢‘ï¼Œå°è¯•ä»åŸå§‹æ–‡ä»¶å¤„ç†ï¼ˆä¸æ¨èï¼‰');
            // é™çº§å¤„ç†ï¼šå¦‚æœ processedAudioBuffer ä¸å­˜åœ¨ï¼Œå°è¯•ä»åŸå§‹æ–‡ä»¶å¤„ç†
            // ä½†è¿™ä¸åº”è¯¥å‘ç”Ÿï¼Œå› ä¸º processAudio åº”è¯¥å·²ç»å¤„ç†äº†éŸ³é¢‘
        }

        // åˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘æµ
        const combinedStream = new MediaStream();
        videoStream.getVideoTracks().forEach(track => combinedStream.addTrack(track));
        if (audioStream) {
            audioStream.getAudioTracks().forEach(track => combinedStream.addTrack(track));
        }

        // åˆ›å»º MediaRecorder
        const mimeTypes = [
            'video/webm;codecs=vp9,opus',
            'video/webm;codecs=vp8,opus',
            'video/webm'
        ];
        
        let selectedMimeType = null;
        for (const mimeType of mimeTypes) {
            if (MediaRecorder.isTypeSupported(mimeType)) {
                selectedMimeType = mimeType;
                break;
            }
        }
        
        if (!selectedMimeType) {
            throw new Error('æµè§ˆå™¨ä¸æ”¯æŒè§†é¢‘å½•åˆ¶');
        }
        
        console.log('ä½¿ç”¨ MIME ç±»å‹:', selectedMimeType);
        const mediaRecorder = new MediaRecorder(combinedStream, {
            mimeType: selectedMimeType,
            videoBitsPerSecond: 2500000
        });

        const chunks = [];
        
        return new Promise((resolve, reject) => {
            mediaRecorder.ondataavailable = (event) => {
                if (event.data && event.data.size > 0) {
                    chunks.push(event.data);
                }
            };

            mediaRecorder.onstop = () => {
                const videoBlob = new Blob(chunks, { type: selectedMimeType });
                console.log('è§†é¢‘åˆæˆå®Œæˆï¼Œå¤§å°:', (videoBlob.size / 1024 / 1024).toFixed(2), 'MB');
                
                // æ¸…ç†æµ
                videoStream.getTracks().forEach(track => track.stop());
                if (audioStream) {
                    audioStream.getTracks().forEach(track => track.stop());
                }
                
                resolve(videoBlob);
            };

            mediaRecorder.onerror = (error) => {
                console.error('MediaRecorder é”™è¯¯:', error);
                reject(new Error('è§†é¢‘å½•åˆ¶å¤±è´¥: ' + error.message));
            };

            // å¼€å§‹å½•åˆ¶
            mediaRecorder.start();

            // é€å¸§ç»˜åˆ¶
            let frameIndex = 0;
            const drawFrame = () => {
                if (frameIndex >= frames.length) {
                    // ç­‰å¾…éŸ³é¢‘æ’­æ”¾å®Œæˆï¼ˆå¦‚æœæœ‰ï¼‰
                    const videoDuration = frames.length / fps;
                    setTimeout(() => {
                        mediaRecorder.stop();
                    }, Math.max(0, (videoDuration - (frameIndex / fps)) * 1000));
                    return;
                }

                // ç»˜åˆ¶å½“å‰å¸§
                ctx.putImageData(frames[frameIndex], 0, 0);
                frameIndex++;

                // ç­‰å¾…ä¸‹ä¸€å¸§ï¼ˆ30fps = 33.33ms per frameï¼‰
                setTimeout(drawFrame, 1000 / fps);
            };

            // å¼€å§‹ç»˜åˆ¶ç¬¬ä¸€å¸§
            drawFrame();
        });
    }

    updateStatus(type, message) {
        const statusElement = document.getElementById('status');
        statusElement.className = `status ${type}`;
        statusElement.textContent = message;
        statusElement.classList.remove('hidden');
    }

    updateProgress(percent) {
        const progressBar = document.getElementById('progressBar');
        const progressFill = document.getElementById('progressFill');
        
        progressBar.classList.remove('hidden');
        progressFill.style.width = `${percent}%`;
        progressFill.textContent = `${percent}%`;
    }
}

// åˆå§‹åŒ–åº”ç”¨
document.addEventListener('DOMContentLoaded', () => {
    window.liteAvatar = new LiteAvatarWeb();
});

